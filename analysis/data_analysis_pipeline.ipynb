{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:40.806733Z",
     "iopub.status.busy": "2026-02-28T18:25:40.806606Z",
     "iopub.status.idle": "2026-02-28T18:25:42.114348Z",
     "shell.execute_reply": "2026-02-28T18:25:42.113832Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "from typing import Optional\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, levene, fligner, wilcoxon, chi2, zscore, gaussian_kde\n",
    "import pingouin as pg\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pingouin\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy.linalg\")\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.115704Z",
     "iopub.status.busy": "2026-02-28T18:25:42.115573Z",
     "iopub.status.idle": "2026-02-28T18:25:42.118711Z",
     "shell.execute_reply": "2026-02-28T18:25:42.118376Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Preprocessing toggle ---\n",
    "RECREATE_PREPROCESSED = False\n",
    "\n",
    "# --- Paths ---\n",
    "RAW_DATA_DIR = Path(\"../data/experiment/raw_data\")\n",
    "PREPROCESSED_DIR = Path(tempfile.mkdtemp(prefix=\"preprocessing_\"))\n",
    "# PREPROCESSED_DIR = Path(\"../data/experiment/data_preprocessed\")  # Final path\n",
    "DATA_DIR = Path(\"../data/experiment/data_preprocessed\")\n",
    "\n",
    "# --- Color palette ---\n",
    "COLORS = {\n",
    "    \"primary_dark\": \"#000000\",\n",
    "    \"teal\": \"#4A8A94\",\n",
    "    \"pink\": \"#E5A3B8\",\n",
    "    \"white\": \"#FFFFFF\",\n",
    "    \"teal_dark\": \"#2E5A62\",\n",
    "    \"pink_dark\": \"#D47A96\",\n",
    "}\n",
    "\n",
    "CONDITION_COLORS = {\n",
    "    \"sequential\": COLORS[\"teal\"],\n",
    "    \"interrupted\": COLORS[\"pink\"],\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.color\": COLORS[\"primary_dark\"],\n",
    "    \"axes.labelcolor\": COLORS[\"primary_dark\"],\n",
    "    \"xtick.color\": COLORS[\"primary_dark\"],\n",
    "    \"ytick.color\": COLORS[\"primary_dark\"],\n",
    "    \"axes.edgecolor\": COLORS[\"primary_dark\"],\n",
    "    \"figure.facecolor\": COLORS[\"white\"],\n",
    "    \"axes.facecolor\": COLORS[\"white\"],\n",
    "})\n",
    "\n",
    "# --- Analysis constants ---\n",
    "ACC_THRESH = 0.85\n",
    "IQR_K = 2.5\n",
    "ALPHA = 0.05\n",
    "WITHIN = [\"COND_interruption_condition\", \"COND_nback_level\"]\n",
    "SUBJECT = \"participant_id\"\n",
    "GROUP_COLS = [\"participant_id\", \"COND_interruption_condition\", \"COND_nback_level\"]\n",
    "CONDITION_ORDER = [\"Seq-Easy\", \"Seq-Hard\", \"Int-Easy\", \"Int-Hard\"]\n",
    "\n",
    "TRIAL_DVS = [\n",
    "    \"OUT_normalized_absolute_error\",\n",
    "    \"OUT_time_estimation_ratio\",\n",
    "    \"OUT_time_per_letter\",\n",
    "    \"OUT_actual_trial_duration_sec\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.119889Z",
     "iopub.status.busy": "2026-02-28T18:25:42.119821Z",
     "iopub.status.idle": "2026-02-28T18:25:42.126454Z",
     "shell.execute_reply": "2026-02-28T18:25:42.126083Z"
    }
   },
   "outputs": [],
   "source": [
    "def _latest_output_csv(participant_dir: Path, pid: str) -> Optional[Path]:\n",
    "    \"\"\"Return the Multitasking-Experiment file with the most recent timestamp.\"\"\"\n",
    "    pattern = f\"{pid}_Multitasking_Experiment_UU_*.csv\"\n",
    "    candidates = sorted(participant_dir.glob(pattern))\n",
    "    return candidates[-1] if candidates else None\n",
    "\n",
    "\n",
    "def collect_demographics(raw_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame with participant_id, gender, age.\"\"\"\n",
    "    records = []\n",
    "    for pdir in sorted(raw_dir.glob(\"part_*\")):\n",
    "        m = re.fullmatch(r\"part_(\\d{6})\", pdir.name)\n",
    "        if m is None:\n",
    "            continue\n",
    "        pid = m.group(1)\n",
    "        out_csv = _latest_output_csv(pdir, pid)\n",
    "        if out_csv is None:\n",
    "            continue\n",
    "        demo_row = pd.read_csv(\n",
    "            out_csv,\n",
    "            usecols=lambda c: c in {\"cm_gender\", \"cm_age\"},\n",
    "            nrows=7,\n",
    "        ).iloc[6]\n",
    "        records.append({\n",
    "            \"participant_id\": pid,\n",
    "            \"gender\": demo_row.get(\"cm_gender\", np.nan),\n",
    "            \"age\": pd.to_numeric(demo_row.get(\"cm_age\", np.nan), errors=\"coerce\"),\n",
    "        })\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "def preprocess_participant(participant_dir: Path, output_dir: Path) -> None:\n",
    "    \"\"\"Full cleaning pipeline for one participant directory.\"\"\"\n",
    "    match = re.fullmatch(r\"part_(\\d{6})\", participant_dir.name)\n",
    "    if match is None:\n",
    "        return\n",
    "    pid = match.group(1)\n",
    "    output_csv = _latest_output_csv(participant_dir, pid)\n",
    "    cond_csv = participant_dir / f\"participant_{pid}.csv\"\n",
    "    if output_csv is None or not cond_csv.exists():\n",
    "        print(f\"Missing file(s) for participant {pid}; skipped.\")\n",
    "        return\n",
    "\n",
    "    raw = pd.read_csv(output_csv)\n",
    "    mask = raw[\"cm_experiment_phase\"].isin([\"practice\", \"main\"]) & raw[\"cm_global_trial_number\"].notna()\n",
    "    df = raw.loc[mask].copy()\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    keep = [\n",
    "        \"cm_experiment_phase\", \"cm_global_trial_number\", \"cm_block_number\",\n",
    "        \"cm_target_word\", \"cm_target_word_length\", \"cm_interruption_condition\",\n",
    "        \"cm_interrupt_positions\", \"cm_resumption_lag\", \"cm_entered_text\",\n",
    "        \"cm_typing_correct\", \"cm_time_on_primary_task\", \"cm_nback_hits\",\n",
    "        \"cm_nback_misses\", \"cm_nback_false_alarms\", \"cm_nback_correct_rejections\",\n",
    "        \"cm_nback_accuracy\", \"cm_time_estimate_seconds\",\n",
    "        \"cm_actual_trial_duration\", \"cm_actual_trial_duration_sec\",\n",
    "        \"cm_time_estimation_ratio\", \"cm_gender\", \"cm_age\",\n",
    "    ]\n",
    "    working_df = df[keep].copy()\n",
    "\n",
    "    working_df[\"cm_global_trial_number\"] = working_df[\"cm_global_trial_number\"].astype(\"Int64\")\n",
    "    working_df[\"cm_block_number\"] = working_df[\"cm_block_number\"].astype(\"Int64\")\n",
    "    working_df[\"cm_target_word_length\"] = working_df[\"cm_target_word_length\"].astype(\"Int64\")\n",
    "    working_df[\"cm_time_estimate_seconds\"] = working_df[\"cm_time_estimate_seconds\"].astype(\"Int64\")\n",
    "\n",
    "    working_df = working_df.rename(columns={\"cm_global_trial_number\": \"GLOBAL_TRIAL_NUM\"})\n",
    "    rename_map = {c: c.replace(\"cm_\", \"OUT_\", 1) for c in working_df.columns if c.startswith(\"cm_\")}\n",
    "    working_df = working_df.rename(columns=rename_map).reset_index(drop=True)\n",
    "\n",
    "    cond = pd.read_csv(cond_csv).copy()\n",
    "    cond[\"GLOBAL_TRIAL_NUM\"] = pd.Series(range(1, len(cond) + 1), dtype=\"Int64\")\n",
    "    cond = cond.rename(columns={\"n_back\": \"nback_level\"})\n",
    "    cond = cond.rename(columns=lambda c: f\"COND_{c}\" if c != \"GLOBAL_TRIAL_NUM\" else c)\n",
    "\n",
    "    merged = cond.merge(working_df, how=\"left\", on=\"GLOBAL_TRIAL_NUM\")\n",
    "    ordered_cols = (\n",
    "        [\"GLOBAL_TRIAL_NUM\"]\n",
    "        + [c for c in merged.columns if c.startswith(\"COND_\")]\n",
    "        + [c for c in merged.columns if c.startswith(\"OUT_\")]\n",
    "    )\n",
    "    merged = merged[ordered_cols]\n",
    "\n",
    "    # Time perception metrics\n",
    "    merged[\"OUT_time_estimation_ratio\"] = (\n",
    "        merged[\"OUT_time_estimate_seconds\"] / merged[\"OUT_actual_trial_duration_sec\"]\n",
    "    )\n",
    "    subjective = merged[\"OUT_time_estimate_seconds\"]\n",
    "    objective = merged[\"OUT_actual_trial_duration_sec\"]\n",
    "    merged[\"OUT_normalized_absolute_error\"] = np.abs(subjective - objective) / objective\n",
    "    merged[\"OUT_estimation_direction\"] = np.select(\n",
    "        [merged[\"OUT_time_estimation_ratio\"] > 1, merged[\"OUT_time_estimation_ratio\"] < 1],\n",
    "        [1, -1], default=0,\n",
    "    )\n",
    "\n",
    "    # Performance features\n",
    "    merged[\"OUT_time_per_letter\"] = (\n",
    "        merged[\"OUT_time_on_primary_task\"] / merged[\"OUT_target_word_length\"].replace({0: np.nan})\n",
    "    )\n",
    "    entered = merged[\"OUT_entered_text\"].astype(str).fillna(\"\")\n",
    "    target = merged[\"OUT_target_word\"].astype(str).fillna(\"\")\n",
    "    merged[\"OUT_typing_distance\"] = [\n",
    "        Levenshtein.distance(e, t) for e, t in zip(entered, target)\n",
    "    ]\n",
    "\n",
    "    out_file = output_dir / f\"participant_{pid}_output_CLEAN.csv\"\n",
    "    merged.to_csv(out_file, index=False)\n",
    "    print(f\"Participant {pid}: processed -> {out_file}\")\n",
    "\n",
    "\n",
    "def preprocess_participants(raw_dir: Path, output_dir: Path) -> None:\n",
    "    \"\"\"Run preprocessing for all participant directories.\"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for pdir in sorted(raw_dir.glob(\"part_*\")):\n",
    "        if pdir.is_dir():\n",
    "            preprocess_participant(pdir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.127408Z",
     "iopub.status.busy": "2026-02-28T18:25:42.127345Z",
     "iopub.status.idle": "2026-02-28T18:25:42.128901Z",
     "shell.execute_reply": "2026-02-28T18:25:42.128605Z"
    }
   },
   "outputs": [],
   "source": [
    "if RECREATE_PREPROCESSED:\n",
    "    preprocess_participants(RAW_DATA_DIR, PREPROCESSED_DIR)\n",
    "else:\n",
    "    print(\"Preprocessing skipped (RECREATE_PREPROCESSED = False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.143622Z",
     "iopub.status.busy": "2026-02-28T18:25:42.143524Z",
     "iopub.status.idle": "2026-02-28T18:25:42.170463Z",
     "shell.execute_reply": "2026-02-28T18:25:42.170052Z"
    }
   },
   "outputs": [],
   "source": [
    "demo_df = collect_demographics(RAW_DATA_DIR)\n",
    "n = len(demo_df)\n",
    "print(f\"Participants: N = {n}\")\n",
    "print(f\"\\nGender counts\")\n",
    "print(demo_df[\"gender\"].value_counts(dropna=False))\n",
    "if demo_df[\"age\"].notna().any():\n",
    "    m = demo_df[\"age\"].mean()\n",
    "    sd = demo_df[\"age\"].std()\n",
    "    print(f\"\\nAge: M = {m:.1f}, SD = {sd:.1f} (range {int(demo_df['age'].min())}\\u2013{int(demo_df['age'].max())})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.171650Z",
     "iopub.status.busy": "2026-02-28T18:25:42.171579Z",
     "iopub.status.idle": "2026-02-28T18:25:42.179748Z",
     "shell.execute_reply": "2026-02-28T18:25:42.179389Z"
    }
   },
   "outputs": [],
   "source": [
    "def coefficient_of_variation(x):\n",
    "    \"\"\"CV = SD / Mean.\"\"\"\n",
    "    mean_x = np.mean(x)\n",
    "    return np.std(x, ddof=1) / mean_x if mean_x != 0 else np.nan\n",
    "\n",
    "\n",
    "def flag_outliers_iqr(series, k=IQR_K):\n",
    "    \"\"\"Return boolean mask flagging values outside k * IQR.\"\"\"\n",
    "    q1, q3 = series.quantile(0.25), series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return (series < q1 - k * iqr) | (series > q3 + k * iqr)\n",
    "\n",
    "\n",
    "def flag_outliers_iqr_grouped(df, dv, group_cols, k=IQR_K):\n",
    "    \"\"\"Flag outlier trials within each participant x condition cell using IQR.\"\"\"\n",
    "    mask = pd.Series(False, index=df.index)\n",
    "    for _, grp in df.groupby(group_cols):\n",
    "        if len(grp) < 4:\n",
    "            continue\n",
    "        flags = flag_outliers_iqr(grp[dv], k=k)\n",
    "        mask.loc[grp.index] = flags\n",
    "    return mask\n",
    "\n",
    "\n",
    "def winsorise_to_median(series, flags):\n",
    "    \"\"\"Replace flagged values with the series median.\"\"\"\n",
    "    result = series.copy()\n",
    "    result[flags] = series[~flags].median()\n",
    "    return result\n",
    "\n",
    "\n",
    "def mahalanobis_distances(df, cols):\n",
    "    \"\"\"Compute Mahalanobis distances for multivariate outlier detection.\"\"\"\n",
    "    X = df[cols].values\n",
    "    mean = X.mean(axis=0)\n",
    "    cov = np.cov(X.T)\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    diff = X - mean\n",
    "    md = np.sqrt(np.sum(diff @ cov_inv * diff, axis=1))\n",
    "    p_values = 1 - chi2.cdf(md ** 2, df=len(cols))\n",
    "    return md, p_values\n",
    "\n",
    "\n",
    "def normality_check(agg_df, dv, within, subject):\n",
    "    \"\"\"Fit OLS model mirroring RM-ANOVA, test residual normality, show QQ-plot.\"\"\"\n",
    "    formula = f\"{dv} ~ C({within[0]}) * C({within[1]})\"\n",
    "    model = sm.OLS.from_formula(formula, data=agg_df).fit()\n",
    "    resid = model.resid\n",
    "    w_stat, p_val = shapiro(resid)\n",
    "    print(f\"\\nShapiro-Wilk on residuals of {dv}: W = {w_stat:.3f}, p = {p_val:.4f}\")\n",
    "    if p_val < ALPHA:\n",
    "        print(f\"  -> Residuals significantly deviate from normality (p < {ALPHA}).\")\n",
    "    else:\n",
    "        print(f\"  -> Residuals approximately normal (p >= {ALPHA}).\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    pg.qqplot(resid, dist=\"norm\", ax=ax)\n",
    "    ax.set_title(f\"QQ-Plot: {dv}\", fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return w_stat, p_val\n",
    "\n",
    "\n",
    "def variance_equality_tests(agg_df, dv, group_col):\n",
    "    \"\"\"Run Brown-Forsythe and Fligner-Killeen tests.\"\"\"\n",
    "    groups = [g[dv].values for _, g in agg_df.groupby(group_col)]\n",
    "    bf_stat, bf_p = levene(*groups, center=\"median\")\n",
    "    fk_stat, fk_p = fligner(*groups)\n",
    "    print(f\"\\nVariance equality for {dv}:\")\n",
    "    print(f\"  Brown-Forsythe: F = {bf_stat:.2f}, p = {bf_p:.3f}\")\n",
    "    print(f\"  Fligner-Killeen: chi2 = {fk_stat:.2f}, p = {fk_p:.3f}\")\n",
    "    return (bf_stat, bf_p), (fk_stat, fk_p)\n",
    "\n",
    "\n",
    "def report_rm_anova(df_long, dv):\n",
    "    \"\"\"Run and print a 2-factor repeated-measures ANOVA with post-hoc tests.\"\"\"\n",
    "    aov = pg.rm_anova(\n",
    "        data=df_long, dv=dv, within=WITHIN, subject=SUBJECT, detailed=True\n",
    "    )\n",
    "    nice = (\n",
    "        aov.rename(columns={\"Source\": \"Effect\", \"ddof1\": \"df1\", \"ddof2\": \"df2\", \"p_unc\": \"p\"})\n",
    "        .loc[:, [\"Effect\", \"SS\", \"df1\", \"df2\", \"MS\", \"F\", \"p\", \"ng2\"]]\n",
    "        .round({\"SS\": 4, \"MS\": 4, \"F\": 3, \"p\": 4, \"ng2\": 3})\n",
    "    )\n",
    "    nice[\"sig\"] = np.where(nice[\"p\"] < ALPHA, \"*\", \"\")\n",
    "    print(f\"\\n=== Repeated-measures ANOVA on {dv} ===\")\n",
    "    print(nice.to_string(index=False))\n",
    "\n",
    "    ph = pg.pairwise_tests(\n",
    "        data=df_long, dv=dv, within=WITHIN, subject=SUBJECT,\n",
    "        padjust=\"holm\", parametric=True, effsize=\"hedges\",\n",
    "    )\n",
    "    sig_ph = ph[ph[\"p_corr\"] < ALPHA]\n",
    "    print(f\"\\nPost-hoc paired t-tests (Holm-corrected, \\u03b1 = .05)\")\n",
    "    if sig_ph.empty:\n",
    "        print(\"  \\u2013 none survive correction.\")\n",
    "    else:\n",
    "        keep = (\n",
    "            sig_ph[[\"A\", \"B\", \"T\", \"dof\", \"p_corr\", \"hedges\"]]\n",
    "            .rename(columns={\"A\": \"Cell A\", \"B\": \"Cell B\", \"p_corr\": \"p_Holm\", \"hedges\": \"g\"})\n",
    "            .round({\"T\": 3, \"p_Holm\": 4, \"g\": 3})\n",
    "        )\n",
    "        print(keep.to_string(index=False))\n",
    "    return aov\n",
    "\n",
    "\n",
    "def art_anova(df, dv, within, subject):\n",
    "    \"\"\"Aligned Rank Transform ANOVA (Wobbrock et al., 2011).\"\"\"\n",
    "    from scipy.stats import rankdata\n",
    "    data = df.copy()\n",
    "    results = []\n",
    "    effects = within + [\" x \".join(within)]\n",
    "\n",
    "    for effect in effects:\n",
    "        aligned = data[dv].copy()\n",
    "        factors = effect.split(\" x \") if \" x \" in effect else [effect]\n",
    "        other_factors = [f for f in within if f not in factors]\n",
    "\n",
    "        grand_mean = data[dv].mean()\n",
    "        for of in other_factors:\n",
    "            group_means = data.groupby(of)[dv].transform(\"mean\")\n",
    "            aligned = aligned - group_means + grand_mean\n",
    "        if len(factors) < len(within):\n",
    "            interaction_mean = data.groupby(within)[dv].transform(\"mean\")\n",
    "            cell_effect = interaction_mean - grand_mean\n",
    "            for f in within:\n",
    "                cell_effect = cell_effect - (data.groupby(f)[dv].transform(\"mean\") - grand_mean)\n",
    "            aligned = aligned - cell_effect\n",
    "\n",
    "        data[f\"aligned_{effect}\"] = rankdata(aligned)\n",
    "        aov = pg.rm_anova(\n",
    "            data=data, dv=f\"aligned_{effect}\", within=within, subject=subject, detailed=True\n",
    "        )\n",
    "        if \" x \" in effect:\n",
    "            interaction_source = f\"{within[0]} * {within[1]}\"\n",
    "            row = aov[aov[\"Source\"] == interaction_source].iloc[0]\n",
    "        else:\n",
    "            row = aov[aov[\"Source\"] == effect].iloc[0]\n",
    "        results.append({\n",
    "            \"Effect\": effect,\n",
    "            \"F\": row[\"F\"],\n",
    "            \"df1\": row[\"ddof1\"],\n",
    "            \"df2\": row[\"ddof2\"],\n",
    "            \"p\": row[\"p_unc\"],\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(results).round({\"F\": 2, \"p\": 4})\n",
    "    result_df[\"sig\"] = np.where(result_df[\"p\"] < ALPHA, \"*\", \"\")\n",
    "    print(f\"\\n=== ART ANOVA on {dv} ===\")\n",
    "    print(result_df.to_string(index=False))\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def create_condition_label(row):\n",
    "    \"\"\"Map interruption x nback factors to a short label.\"\"\"\n",
    "    interruption = \"Int\" if \"interrupted\" in str(row[\"COND_interruption_condition\"]) else \"Seq\"\n",
    "    nback = \"Easy\" if row[\"COND_nback_level\"] == 1 else \"Hard\"\n",
    "    return f\"{interruption}-{nback}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.180752Z",
     "iopub.status.busy": "2026-02-28T18:25:42.180688Z",
     "iopub.status.idle": "2026-02-28T18:25:42.214353Z",
     "shell.execute_reply": "2026-02-28T18:25:42.213971Z"
    }
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "for filepath in sorted(DATA_DIR.glob(\"participant_*_output_CLEAN.csv\")):\n",
    "    pid_match = re.search(r\"participant_(\\d+)_output_CLEAN\\.csv\", filepath.name)\n",
    "    if not pid_match:\n",
    "        continue\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[\"participant_id\"] = pid_match.group(1)\n",
    "    frames.append(df)\n",
    "\n",
    "df_all = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "numeric_cols = [\n",
    "    \"OUT_time_estimation_ratio\", \"OUT_normalized_absolute_error\",\n",
    "    \"OUT_time_estimate_seconds\", \"OUT_nback_accuracy\",\n",
    "    \"OUT_time_per_letter\", \"OUT_actual_trial_duration_sec\",\n",
    "    \"OUT_typing_distance\", \"OUT_resumption_lag\",\n",
    "]\n",
    "for col in numeric_cols:\n",
    "    if col in df_all.columns:\n",
    "        df_all[col] = pd.to_numeric(df_all[col], errors=\"coerce\")\n",
    "\n",
    "df_all[\"condition_label\"] = df_all.apply(create_condition_label, axis=1)\n",
    "df_all[\"condition_label\"] = pd.Categorical(\n",
    "    df_all[\"condition_label\"], categories=CONDITION_ORDER, ordered=True,\n",
    ")\n",
    "\n",
    "print(f\"Loaded {df_all['participant_id'].nunique()} participants, {len(df_all)} total trials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.215392Z",
     "iopub.status.busy": "2026-02-28T18:25:42.215326Z",
     "iopub.status.idle": "2026-02-28T18:25:42.395043Z",
     "shell.execute_reply": "2026-02-28T18:25:42.394706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter to main-phase trials\n",
    "df_main = df_all.query(\"OUT_experiment_phase == 'main'\").copy()\n",
    "print(f\"Main-phase trials: {len(df_main)}\")\n",
    "\n",
    "# Exclude trials with low N-back accuracy\n",
    "df_main = df_main[df_main[\"OUT_nback_accuracy\"] >= ACC_THRESH].copy()\n",
    "print(f\"After accuracy filter (>= {ACC_THRESH}): {len(df_main)} valid trials\")\n",
    "\n",
    "# Trial-level outlier detection using IQR (k=2.5)\n",
    "# Applied to time perception and performance DVs, NOT typing_error\n",
    "for dv in TRIAL_DVS:\n",
    "    if dv in df_main.columns:\n",
    "        df_main[f\"outlier_{dv}\"] = flag_outliers_iqr_grouped(\n",
    "            df_main, dv, GROUP_COLS, k=IQR_K\n",
    "        )\n",
    "\n",
    "outlier_mask = df_main.filter(regex=r\"^outlier_\").any(axis=1)\n",
    "n_removed = outlier_mask.sum()\n",
    "df_clean = df_main[~outlier_mask].copy()\n",
    "\n",
    "pct = 100 * n_removed / len(df_main)\n",
    "print(f\"\\nOutlier removal: {n_removed} trials ({pct:.1f}%)\")\n",
    "print(f\"Final dataset: {len(df_clean)} trials across {df_clean['participant_id'].nunique()} participants\")\n",
    "\n",
    "# Trials per participant\n",
    "trials_per_p = df_clean.groupby(\"participant_id\").size()\n",
    "print(f\"Trials per participant: M = {trials_per_p.mean():.1f}, \"\n",
    "      f\"SD = {trials_per_p.std():.1f}, range {trials_per_p.min()}\\u2013{trials_per_p.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.396455Z",
     "iopub.status.busy": "2026-02-28T18:25:42.396365Z",
     "iopub.status.idle": "2026-02-28T18:25:42.417816Z",
     "shell.execute_reply": "2026-02-28T18:25:42.417292Z"
    }
   },
   "outputs": [],
   "source": [
    "# General trial properties\n",
    "print(\"=== General Trial Properties ===\")\n",
    "for col, label, fmt in [\n",
    "    (\"OUT_actual_trial_duration_sec\", \"Trial duration (s)\", \".1f\"),\n",
    "    (\"OUT_target_word_length\", \"Word length (chars)\", \".1f\"),\n",
    "]:\n",
    "    if col in df_clean.columns:\n",
    "        m = df_clean[col].mean()\n",
    "        sd = df_clean[col].std()\n",
    "        print(f\"  {label}: M = {m:{fmt}}, SD = {sd:{fmt}}\")\n",
    "\n",
    "# Task performance by interruption condition\n",
    "print(\"\\n=== Task Performance by Interruption Condition ===\")\n",
    "for cond in [\"sequential\", \"interrupted\"]:\n",
    "    subset = df_clean[df_clean[\"COND_interruption_condition\"] == cond]\n",
    "    tpl_m = subset[\"OUT_time_per_letter\"].mean()\n",
    "    tpl_sd = subset[\"OUT_time_per_letter\"].std()\n",
    "    te_m = subset[\"OUT_typing_distance\"].mean()\n",
    "    te_sd = subset[\"OUT_typing_distance\"].std()\n",
    "    print(f\"  {cond.capitalize()}: time_per_letter M = {tpl_m:.2f} (SD = {tpl_sd:.2f}), \"\n",
    "          f\"typing_error M = {te_m:.2f} (SD = {te_sd:.2f})\")\n",
    "\n",
    "# Task performance by 2x2 condition\n",
    "print(\"\\n=== Task Performance by 2\\u00d72 Condition ===\")\n",
    "perf_desc = (\n",
    "    df_clean.groupby([\"COND_interruption_condition\", \"COND_nback_level\"])\n",
    "    .agg(\n",
    "        tpl_mean=(\"OUT_time_per_letter\", \"mean\"),\n",
    "        typing_err_mean=(\"OUT_typing_distance\", \"mean\"),\n",
    "    )\n",
    "    .round(3)\n",
    ")\n",
    "display(perf_desc)\n",
    "\n",
    "# Time perception by interruption condition\n",
    "print(\"\\n=== Time Perception by Interruption Condition ===\")\n",
    "for cond in [\"sequential\", \"interrupted\"]:\n",
    "    subset = df_clean[df_clean[\"COND_interruption_condition\"] == cond]\n",
    "    ae_m = subset[\"OUT_normalized_absolute_error\"].mean()\n",
    "    ae_sd = subset[\"OUT_normalized_absolute_error\"].std()\n",
    "    so_m = subset[\"OUT_time_estimation_ratio\"].mean()\n",
    "    so_sd = subset[\"OUT_time_estimation_ratio\"].std()\n",
    "    print(f\"  {cond.capitalize()}: absolute_error M = {ae_m:.3f} (SD = {ae_sd:.3f}), \"\n",
    "          f\"SO_ratio M = {so_m:.3f} (SD = {so_sd:.3f})\")\n",
    "\n",
    "# Time perception by 2x2 condition\n",
    "print(\"\\n=== Time Perception by 2\\u00d72 Condition ===\")\n",
    "# Aggregate at participant level first, then compute condition means\n",
    "tp_part = df_clean.groupby(GROUP_COLS, as_index=False).agg(\n",
    "    mean_abs_error=(\"OUT_normalized_absolute_error\", \"mean\"),\n",
    "    mean_SO_ratio=(\"OUT_time_estimation_ratio\", \"mean\"),\n",
    "    cv_estimate=(\"OUT_time_estimate_seconds\", coefficient_of_variation),\n",
    ")\n",
    "tp_desc = (\n",
    "    tp_part.groupby([\"COND_interruption_condition\", \"COND_nback_level\"])\n",
    "    [[\"mean_abs_error\", \"mean_SO_ratio\", \"cv_estimate\"]]\n",
    "    .mean()\n",
    "    .round(3)\n",
    ")\n",
    "display(tp_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Performance: 2\\u00d72 Repeated-Measures ANOVAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.419384Z",
     "iopub.status.busy": "2026-02-28T18:25:42.419267Z",
     "iopub.status.idle": "2026-02-28T18:25:42.436813Z",
     "shell.execute_reply": "2026-02-28T18:25:42.436383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate to participant x condition level\n",
    "agg_perf = df_clean.groupby(GROUP_COLS, as_index=False).agg(\n",
    "    mean_time_per_letter=(\"OUT_time_per_letter\", \"mean\"),\n",
    "    mean_typing_error=(\"OUT_typing_distance\", \"mean\"),\n",
    ")\n",
    "\n",
    "# Cell-level outlier screening\n",
    "perf_dvs = [\"mean_time_per_letter\", \"mean_typing_error\"]\n",
    "\n",
    "for dv in perf_dvs:\n",
    "    # Univariate: z > 3.29 within each condition cell\n",
    "    agg_perf[\"_outlier_uni\"] = False\n",
    "    for _, grp in agg_perf.groupby([\"COND_interruption_condition\", \"COND_nback_level\"]):\n",
    "        z = zscore(grp[dv], nan_policy=\"omit\")\n",
    "        mask = np.abs(z) > 3.29\n",
    "        agg_perf.loc[grp.index, \"_outlier_uni\"] = mask\n",
    "    n_uni = agg_perf[\"_outlier_uni\"].sum()\n",
    "    if n_uni > 0:\n",
    "        for idx in agg_perf.index[agg_perf[\"_outlier_uni\"]]:\n",
    "            row = agg_perf.loc[idx]\n",
    "            cell_mask = (\n",
    "                (agg_perf[\"COND_interruption_condition\"] == row[\"COND_interruption_condition\"])\n",
    "                & (agg_perf[\"COND_nback_level\"] == row[\"COND_nback_level\"])\n",
    "                & (agg_perf.index != idx)\n",
    "            )\n",
    "            agg_perf.loc[idx, dv] = agg_perf.loc[cell_mask, dv].median()\n",
    "        print(f\"{dv}: {n_uni} univariate outlier(s) winsorised (per-cell z > 3.29).\")\n",
    "    else:\n",
    "        print(f\"{dv}: no univariate outliers (all |z| < 3.29).\")\n",
    "    agg_perf.drop(columns=[\"_outlier_uni\"], inplace=True)\n",
    "\n",
    "# Multivariate: Mahalanobis distance on 4-cell vectors per participant per DV\n",
    "for dv in perf_dvs:\n",
    "    wide = (\n",
    "        agg_perf.pivot(index=\"participant_id\",\n",
    "                       columns=[\"COND_interruption_condition\", \"COND_nback_level\"],\n",
    "                       values=dv)\n",
    "        .dropna()\n",
    "    )\n",
    "    X = wide.values\n",
    "    mean = X.mean(axis=0)\n",
    "    cov = np.cov(X.T)\n",
    "    if np.linalg.det(cov) == 0:\n",
    "        print(f\"{dv}: covariance matrix is singular; skipping multivariate check.\")\n",
    "        continue\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    diff = X - mean\n",
    "    md = np.sqrt(np.sum(diff @ cov_inv * diff, axis=1))\n",
    "    cutoff = np.sqrt(chi2.ppf(1 - 0.001, df=wide.shape[1]))\n",
    "    multi_flags = md > cutoff\n",
    "    n_multi = multi_flags.sum()\n",
    "    if n_multi > 0:\n",
    "        outlier_pids = wide.index[multi_flags]\n",
    "        for pid in outlier_pids:\n",
    "            pid_mask = agg_perf[\"participant_id\"] == pid\n",
    "            cell_median = agg_perf.loc[~pid_mask, dv].median()\n",
    "            agg_perf.loc[pid_mask, dv] = cell_median\n",
    "        print(f\"{dv}: {n_multi} multivariate outlier(s) winsorised.\")\n",
    "    else:\n",
    "        print(f\"{dv}: no multivariate outliers.\")\n",
    "\n",
    "agg_perf[\"condition_label\"] = agg_perf.apply(create_condition_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.437856Z",
     "iopub.status.busy": "2026-02-28T18:25:42.437771Z",
     "iopub.status.idle": "2026-02-28T18:25:42.756434Z",
     "shell.execute_reply": "2026-02-28T18:25:42.755978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normality of residuals\n",
    "for dv in perf_dvs:\n",
    "    normality_check(agg_perf, dv, WITHIN, SUBJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.757622Z",
     "iopub.status.busy": "2026-02-28T18:25:42.757530Z",
     "iopub.status.idle": "2026-02-28T18:25:42.761394Z",
     "shell.execute_reply": "2026-02-28T18:25:42.760990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Variance equality\n",
    "for dv in perf_dvs:\n",
    "    variance_equality_tests(agg_perf, dv, \"condition_label\" if \"condition_label\" in agg_perf.columns else WITHIN[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.762509Z",
     "iopub.status.busy": "2026-02-28T18:25:42.762441Z",
     "iopub.status.idle": "2026-02-28T18:25:42.793109Z",
     "shell.execute_reply": "2026-02-28T18:25:42.792690Z"
    }
   },
   "outputs": [],
   "source": [
    "report_rm_anova(agg_perf, \"mean_time_per_letter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.794293Z",
     "iopub.status.busy": "2026-02-28T18:25:42.794214Z",
     "iopub.status.idle": "2026-02-28T18:25:42.822505Z",
     "shell.execute_reply": "2026-02-28T18:25:42.822134Z"
    }
   },
   "outputs": [],
   "source": [
    "report_rm_anova(agg_perf, \"mean_typing_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.823508Z",
     "iopub.status.busy": "2026-02-28T18:25:42.823427Z",
     "iopub.status.idle": "2026-02-28T18:25:42.880801Z",
     "shell.execute_reply": "2026-02-28T18:25:42.880484Z"
    }
   },
   "outputs": [],
   "source": [
    "# ART ANOVA (robustness check)\n",
    "for dv in perf_dvs:\n",
    "    art_anova(agg_perf, dv, WITHIN, SUBJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:42.881992Z",
     "iopub.status.busy": "2026-02-28T18:25:42.881920Z",
     "iopub.status.idle": "2026-02-28T18:25:43.047971Z",
     "shell.execute_reply": "2026-02-28T18:25:43.047418Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, dv, ylabel, title in [\n",
    "    (axes[0], \"mean_time_per_letter\", \"Time per Letter (s)\", \"Time-per-Letter\"),\n",
    "    (axes[1], \"mean_typing_error\", \"Typing Error (Levenshtein)\", \"Typing Error\"),\n",
    "]:\n",
    "    sns.pointplot(\n",
    "        data=agg_perf, x=\"COND_nback_level\", y=dv,\n",
    "        hue=\"COND_interruption_condition\",\n",
    "        dodge=0.2, markers=[\"o\", \"s\"], linestyles=[\"-\", \"--\"],\n",
    "        palette={\"sequential\": COLORS[\"teal_dark\"], \"interrupted\": COLORS[\"pink_dark\"]},\n",
    "        capsize=0.1, err_kws={\"linewidth\": 2}, ax=ax, legend=False,\n",
    "    )\n",
    "    ax.set_xlabel(\"Task Complexity\", fontsize=11)\n",
    "    ax.set_ylabel(ylabel, fontsize=11)\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels([\"1-back\\n(Easy)\", \"2-back\\n(Hard)\"])\n",
    "    ax.yaxis.grid(True, alpha=0.15, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=COLORS[\"teal_dark\"], linestyle=\"-\", marker=\"o\", markersize=6, label=\"Sequential\"),\n",
    "    Line2D([0], [0], color=COLORS[\"pink_dark\"], linestyle=\"--\", marker=\"s\", markersize=6, label=\"Interrupted\"),\n",
    "]\n",
    "fig.legend(handles=legend_elements, title=\"Condition\", loc=\"upper right\",\n",
    "           bbox_to_anchor=(0.98, 0.98), frameon=True, fontsize=9, title_fontsize=10)\n",
    "fig.suptitle(\"Task Performance: Interaction Plots\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.049774Z",
     "iopub.status.busy": "2026-02-28T18:25:43.049666Z",
     "iopub.status.idle": "2026-02-28T18:25:43.124930Z",
     "shell.execute_reply": "2026-02-28T18:25:43.123555Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "positions = {\n",
    "    ('1', 'sequential'): 4,\n",
    "    ('2', 'sequential'): 3,\n",
    "    ('1', 'interrupted'): 2,\n",
    "    ('2', 'interrupted'): 1\n",
    "}\n",
    "\n",
    "def plot_raincloud(data, y_pos, color, color_dark, ax):\n",
    "    if len(data) == 0:\n",
    "        return\n",
    "    kde = gaussian_kde(data)\n",
    "    x_range = np.linspace(data.min() - 0.3, data.max() + 0.3, 200)\n",
    "    density = kde(x_range)\n",
    "    density = density * 0.6 / density.max()\n",
    "\n",
    "    ax.fill_between(x_range, y_pos, y_pos + density,\n",
    "                    color=color, alpha=0.35, edgecolor=color_dark, linewidth=1.2)\n",
    "\n",
    "    bp = ax.boxplot(data, positions=[y_pos], vert=False, widths=0.06,\n",
    "                    patch_artist=True, showfliers=False,\n",
    "                    boxprops=dict(facecolor=color, alpha=0.85, linewidth=0.8),\n",
    "                    medianprops=dict(color=COLORS['primary_dark'], linewidth=2),\n",
    "                    whiskerprops=dict(color=COLORS['primary_dark'], linewidth=1.2),\n",
    "                    capprops=dict(color=COLORS['primary_dark'], linewidth=1.2))\n",
    "\n",
    "    x_scatter = data\n",
    "    y_scatter = np.full(len(x_scatter), y_pos - 0.12)\n",
    "    y_scatter += np.random.uniform(-0.06, 0, len(x_scatter))\n",
    "    ax.scatter(x_scatter, y_scatter, alpha=0.4, s=30, color=color,\n",
    "               edgecolor=COLORS['primary_dark'], linewidth=0.3)\n",
    "\n",
    "for (nback, condition), y_pos in positions.items():\n",
    "    mask = (agg_perf['COND_nback_level'] == int(nback)) & (agg_perf['COND_interruption_condition'] == condition)\n",
    "    data = agg_perf[mask]['mean_time_per_letter'].values\n",
    "    color = COLORS['teal'] if condition == 'sequential' else COLORS['pink']\n",
    "    color_dark = COLORS['teal_dark'] if condition == 'sequential' else COLORS['pink_dark']\n",
    "    plot_raincloud(data, y_pos, color, color_dark, ax)\n",
    "\n",
    "ax.axhline(y=2.5, color=COLORS['primary_dark'], linestyle=':', alpha=0.2, linewidth=1)\n",
    "ax.set_yticks([4, 3, 2, 1])\n",
    "ax.set_yticklabels(['1-back (Easy)', '2-back (Hard)', '1-back (Easy)', '2-back (Hard)'],\n",
    "                   fontsize=11, color=COLORS['primary_dark'])\n",
    "\n",
    "ax.text(ax.get_xlim()[1] * 1.02, 3.5, 'Sequential', fontsize=12,\n",
    "        color=COLORS['teal_dark'], fontweight='bold', va='center')\n",
    "ax.text(ax.get_xlim()[1] * 1.02, 1.5, 'Interrupted', fontsize=12,\n",
    "        color=COLORS['pink_dark'], fontweight='bold', va='center')\n",
    "\n",
    "ax.set_xlabel('Time-per-Letter (seconds)', fontsize=12, color=COLORS['primary_dark'])\n",
    "ax.set_title('Time-per-Letter by Interruption Condition and Task Complexity',\n",
    "             fontsize=14, fontweight='bold', color=COLORS['primary_dark'], pad=20)\n",
    "\n",
    "ax.text(0.98, 0.96,\n",
    "        'Main Effect of Interruption\\nF(1,25) = 25.39, p < .001\\n\u03b7\u00b2g = .106',\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        ha='right',\n",
    "        va='top',\n",
    "        bbox=dict(boxstyle='round,pad=0.5',\n",
    "                  facecolor='white',\n",
    "                  edgecolor=COLORS['primary_dark'],\n",
    "                  alpha=0.9))\n",
    "\n",
    "ax.xaxis.grid(True, alpha=0.15, linestyle='--', color=COLORS['primary_dark'])\n",
    "ax.set_axisbelow(True)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color(COLORS['primary_dark'])\n",
    "ax.spines['bottom'].set_color(COLORS['primary_dark'])\n",
    "ax.set_ylim(0.5, 4.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumption Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.126626Z",
     "iopub.status.busy": "2026-02-28T18:25:43.126526Z",
     "iopub.status.idle": "2026-02-28T18:25:43.205513Z",
     "shell.execute_reply": "2026-02-28T18:25:43.205084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter to main-phase interrupted trials (from full dataset, before trial-level outlier removal)\n",
    "df_int = df_all.query(\n",
    "    \"OUT_experiment_phase == 'main' and COND_interruption_condition == 'interrupted'\"\n",
    ").copy()\n",
    "\n",
    "# Aggregate by participant x nback_level\n",
    "rl_agg = (\n",
    "    df_int.groupby([\"participant_id\", \"COND_nback_level\"])[\"OUT_resumption_lag\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot to wide format\n",
    "rl_wide = rl_agg.pivot(index=\"participant_id\", columns=\"COND_nback_level\", values=\"OUT_resumption_lag\")\n",
    "rl_wide.columns = [\"RL_1back\", \"RL_2back\"]\n",
    "rl_wide = rl_wide.dropna().reset_index()\n",
    "\n",
    "# IQR outlier screening (k=1.5) and winsorisation\n",
    "for col in [\"RL_1back\", \"RL_2back\"]:\n",
    "    flags = flag_outliers_iqr(rl_wide[col], k=1.5)\n",
    "    n_out = flags.sum()\n",
    "    if n_out > 0:\n",
    "        rl_wide[col] = winsorise_to_median(rl_wide[col], flags)\n",
    "        print(f\"{col}: {n_out} outlier(s) winsorised to median.\")\n",
    "\n",
    "# Difference scores\n",
    "rl_wide[\"diff\"] = rl_wide[\"RL_1back\"] - rl_wide[\"RL_2back\"]\n",
    "\n",
    "# Normality of difference scores\n",
    "w_stat, p_val = shapiro(rl_wide[\"diff\"])\n",
    "print(f\"\\nShapiro-Wilk on difference scores: W({len(rl_wide)}) = {w_stat:.3f}, p = {p_val:.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "pg.qqplot(rl_wide[\"diff\"], dist=\"norm\", ax=ax)\n",
    "ax.set_title(\"QQ-Plot: Resumption Lag Differences\", fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n1-back: M = {rl_wide['RL_1back'].mean():.2f} s, SD = {rl_wide['RL_1back'].std():.2f} s\")\n",
    "print(f\"2-back: M = {rl_wide['RL_2back'].mean():.2f} s, SD = {rl_wide['RL_2back'].std():.2f} s\")\n",
    "print(f\"Mean difference: {rl_wide['diff'].mean():.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.206771Z",
     "iopub.status.busy": "2026-02-28T18:25:43.206677Z",
     "iopub.status.idle": "2026-02-28T18:25:43.210322Z",
     "shell.execute_reply": "2026-02-28T18:25:43.209918Z"
    }
   },
   "outputs": [],
   "source": [
    "x = rl_wide[\"RL_1back\"].values\n",
    "y = rl_wide[\"RL_2back\"].values\n",
    "\n",
    "# Wilcoxon signed-rank test (one-tailed: 1-back < 2-back)\n",
    "wx_stat, wx_p = wilcoxon(x, y, alternative=\"less\")\n",
    "print(f\"Wilcoxon signed-rank test (one-tailed): W = {wx_stat}, p = {wx_p:.4g}\")\n",
    "\n",
    "# Paired t-test (confirmatory)\n",
    "t_result = pg.ttest(x, y, paired=True, alternative=\"less\")\n",
    "t_val = t_result[\"T\"].values[0]\n",
    "t_dof = t_result[\"dof\"].values[0]\n",
    "t_p = t_result[\"p_val\"].values[0]\n",
    "cohen_d = t_result[\"cohen_d\"].values[0]\n",
    "print(f\"\\nPaired t-test (one-tailed): t({t_dof}) = {t_val:.2f}, p = {t_p:.4g}\")\n",
    "print(f\"Cohen's d = {cohen_d:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.211341Z",
     "iopub.status.busy": "2026-02-28T18:25:43.211275Z",
     "iopub.status.idle": "2026-02-28T18:25:43.356223Z",
     "shell.execute_reply": "2026-02-28T18:25:43.355851Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "x_positions = [1, 2]\n",
    "\n",
    "for idx, row in rl_wide.iterrows():\n",
    "    rl_1back = row['RL_1back']\n",
    "    rl_2back = row['RL_2back']\n",
    "\n",
    "    if rl_2back > rl_1back:\n",
    "        line_color = COLORS['pink_dark']\n",
    "        alpha = 0.4\n",
    "    else:\n",
    "        line_color = COLORS['teal_dark']\n",
    "        alpha = 0.7\n",
    "\n",
    "    ax.plot(x_positions, [rl_1back, rl_2back],\n",
    "            color=line_color, linewidth=1, alpha=alpha, zorder=1)\n",
    "\n",
    "    ax.scatter(1, rl_1back, color=COLORS['teal'], s=40,\n",
    "               edgecolor=COLORS['primary_dark'], linewidth=0.5, zorder=2)\n",
    "    ax.scatter(2, rl_2back, color=COLORS['pink'], s=40,\n",
    "               edgecolor=COLORS['primary_dark'], linewidth=0.5, zorder=2)\n",
    "\n",
    "mean_1back = rl_wide['RL_1back'].mean()\n",
    "mean_2back = rl_wide['RL_2back'].mean()\n",
    "\n",
    "ax.plot(x_positions, [mean_1back, mean_2back],\n",
    "        color=COLORS['primary_dark'], linewidth=3, alpha=0.9, zorder=3)\n",
    "\n",
    "ax.scatter(1, mean_1back, color=COLORS['teal_dark'], s=100,\n",
    "           edgecolor=COLORS['primary_dark'], linewidth=2, zorder=4, marker='o')\n",
    "ax.scatter(2, mean_2back, color=COLORS['pink_dark'], s=100,\n",
    "           edgecolor=COLORS['primary_dark'], linewidth=2, zorder=4, marker='o')\n",
    "\n",
    "ax.text(0.9, mean_1back, f'{mean_1back:.2f}s',\n",
    "        ha='right', va='center', fontsize=11, fontweight='bold',\n",
    "        color=COLORS['primary_dark'])\n",
    "ax.text(2.1, mean_2back, f'{mean_2back:.2f}s',\n",
    "        ha='left', va='center', fontsize=11, fontweight='bold',\n",
    "        color=COLORS['primary_dark'])\n",
    "\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(['1-back\\n(Easy)', '2-back\\n(Hard)'],\n",
    "                   fontsize=12, color=COLORS['primary_dark'])\n",
    "ax.set_ylabel('Resumption Lag (seconds)', fontsize=12, color=COLORS['primary_dark'])\n",
    "ax.set_title('Resumption Lag by Task Complexity',\n",
    "             fontsize=14, fontweight='bold', color=COLORS['primary_dark'])\n",
    "\n",
    "ax.yaxis.grid(True, alpha=0.2, linestyle='--', color=COLORS['primary_dark'])\n",
    "ax.set_axisbelow(True)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color(COLORS['primary_dark'])\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_xlim(0.5, 2.5)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor=COLORS['teal_dark'],\n",
    "           markersize=8, label=f'1-back: {mean_1back:.2f}s'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor=COLORS['pink_dark'],\n",
    "           markersize=8, label=f'2-back: {mean_2back:.2f}s')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', frameon=True,\n",
    "          fontsize=10, edgecolor=COLORS['primary_dark'])\n",
    "\n",
    "effect = mean_2back - mean_1back\n",
    "ax.text(1, 0.98,\n",
    "        f'Mean Difference: +{effect:.2f}s\\nWilcoxon W = 19.0, p < .001\\nCohen\\'s d = 1.08',\n",
    "        transform=ax.transAxes,\n",
    "        ha='right', va='top', fontsize=10,\n",
    "        bbox=dict(boxstyle='round,pad=0.5', facecolor=COLORS['white'],\n",
    "                  edgecolor=COLORS['primary_dark'], alpha=0.9))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects of Interruption Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.357594Z",
     "iopub.status.busy": "2026-02-28T18:25:43.357503Z",
     "iopub.status.idle": "2026-02-28T18:25:43.404494Z",
     "shell.execute_reply": "2026-02-28T18:25:43.404172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data: interrupted trials with nback duration\n",
    "df_dur = df_int.copy()\n",
    "\n",
    "# Compute nback duration column if not present\n",
    "if \"OUT_nback_duration\" not in df_dur.columns:\n",
    "    nback_dur_candidates = [c for c in df_dur.columns if \"nback\" in c.lower() and \"duration\" in c.lower()]\n",
    "    if nback_dur_candidates:\n",
    "        nback_dur_col = nback_dur_candidates[0]\n",
    "    else:\n",
    "        # Approximate from trial duration - time on primary task\n",
    "        df_dur[\"nback_duration\"] = (\n",
    "            df_dur[\"OUT_actual_trial_duration_sec\"]\n",
    "            - df_dur[\"OUT_time_on_primary_task\"] / 1000.0\n",
    "        )\n",
    "        nback_dur_col = \"nback_duration\"\n",
    "else:\n",
    "    nback_dur_col = \"OUT_nback_duration\"\n",
    "\n",
    "df_dur[\"nback_duration_s\"] = pd.to_numeric(df_dur[nback_dur_col], errors=\"coerce\")\n",
    "# If duration is in ms, convert to seconds\n",
    "if df_dur[\"nback_duration_s\"].median() > 100:\n",
    "    df_dur[\"nback_duration_s\"] = df_dur[\"nback_duration_s\"] / 1000.0\n",
    "\n",
    "# Bivariate correlations\n",
    "print(\"=== Bivariate Correlations (interrupted trials) ===\")\n",
    "for dv, label in [(\"OUT_resumption_lag\", \"resumption_lag\"), (\"OUT_typing_distance\", \"typing_error\")]:\n",
    "    subset = df_dur[[\"nback_duration_s\", dv]].dropna()\n",
    "    r, p = stats.pearsonr(subset[\"nback_duration_s\"], subset[dv])\n",
    "    print(f\"  Duration vs {label}: r({len(subset)-2}) = {r:.3f}, p = {p:.3f}\")\n",
    "\n",
    "# LMM 1: resumption_lag\n",
    "print(\"\\n=== LMM: Resumption Lag ===\")\n",
    "df_lmm = df_dur[[\"participant_id\", \"COND_nback_level\", \"nback_duration_s\", \"OUT_resumption_lag\"]].dropna()\n",
    "df_lmm[\"nback_level\"] = df_lmm[\"COND_nback_level\"].astype(str)\n",
    "md1 = smf.mixedlm(\"OUT_resumption_lag ~ C(nback_level) * nback_duration_s\",\n",
    "                   data=df_lmm, groups=df_lmm[\"participant_id\"]).fit()\n",
    "print(md1.summary().tables[1])\n",
    "\n",
    "# LMM 2: typing_error\n",
    "print(\"\\n=== LMM: Typing Error ===\")\n",
    "df_lmm2 = df_dur[[\"participant_id\", \"COND_nback_level\", \"nback_duration_s\", \"OUT_typing_distance\"]].dropna()\n",
    "df_lmm2[\"nback_level\"] = df_lmm2[\"COND_nback_level\"].astype(str)\n",
    "md2 = smf.mixedlm(\"OUT_typing_distance ~ C(nback_level) * nback_duration_s\",\n",
    "                   data=df_lmm2, groups=df_lmm2[\"participant_id\"]).fit()\n",
    "print(md2.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.405788Z",
     "iopub.status.busy": "2026-02-28T18:25:43.405716Z",
     "iopub.status.idle": "2026-02-28T18:25:43.510202Z",
     "shell.execute_reply": "2026-02-28T18:25:43.509868Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.lmplot(\n",
    "    data=df_dur,\n",
    "    x='nback_duration_s',\n",
    "    y='OUT_resumption_lag',\n",
    "    hue='COND_nback_level',\n",
    "    height=6,\n",
    "    aspect=1.2\n",
    ")\n",
    "\n",
    "plt.title('Resumption Lag by N-Back Duration and Complexity', fontsize=16)\n",
    "plt.xlabel('N-Back Interruption Duration (s)', fontsize=12)\n",
    "plt.ylabel('Resumption Lag (s)', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.511394Z",
     "iopub.status.busy": "2026-02-28T18:25:43.511308Z",
     "iopub.status.idle": "2026-02-28T18:25:43.711199Z",
     "shell.execute_reply": "2026-02-28T18:25:43.710709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Repeated-measures correlation: Duration vs Resumption Lag\n",
    "rm_corr_rl = pg.rm_corr(data=df_lmm, x='nback_duration_s', y='OUT_resumption_lag', subject='participant_id')\n",
    "display(rm_corr_rl)\n",
    "\n",
    "sns.lmplot(\n",
    "    data=df_lmm,\n",
    "    x='nback_duration_s',\n",
    "    y='OUT_resumption_lag',\n",
    "    height=6,\n",
    "    aspect=1.2,\n",
    "    line_kws={'color': 'red'}\n",
    ")\n",
    "\n",
    "plt.title('Overall Relationship Between Interruption Duration and Resumption Lag', fontsize=16)\n",
    "plt.xlabel('N-Back Interruption Duration (s)', fontsize=12)\n",
    "plt.ylabel('Resumption Lag (s)', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.712834Z",
     "iopub.status.busy": "2026-02-28T18:25:43.712736Z",
     "iopub.status.idle": "2026-02-28T18:25:43.868758Z",
     "shell.execute_reply": "2026-02-28T18:25:43.868381Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.lmplot(\n",
    "    data=df_dur,\n",
    "    x='nback_duration_s',\n",
    "    y='OUT_typing_distance',\n",
    "    hue='COND_nback_level',\n",
    "    height=6,\n",
    "    aspect=1.2\n",
    ")\n",
    "\n",
    "plt.title('Typing Errors by N-Back Duration and Complexity', fontsize=16)\n",
    "plt.xlabel('N-Back Interruption Duration (s)', fontsize=12)\n",
    "plt.ylabel('Typing Error (Levenshtein distance)', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-back Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.870152Z",
     "iopub.status.busy": "2026-02-28T18:25:43.870067Z",
     "iopub.status.idle": "2026-02-28T18:25:43.876016Z",
     "shell.execute_reply": "2026-02-28T18:25:43.875623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate by participant x nback_level\n",
    "nback_agg = (\n",
    "    df_clean.groupby([\"participant_id\", \"COND_nback_level\"])[\"OUT_nback_accuracy\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "nback_wide = nback_agg.pivot(index=\"participant_id\", columns=\"COND_nback_level\", values=\"OUT_nback_accuracy\")\n",
    "nback_wide.columns = [\"acc_1back\", \"acc_2back\"]\n",
    "nback_wide = nback_wide.dropna().reset_index()\n",
    "\n",
    "nback_wide[\"diff\"] = nback_wide[\"acc_1back\"] - nback_wide[\"acc_2back\"]\n",
    "\n",
    "print(f\"1-back accuracy: M = {nback_wide['acc_1back'].mean():.3f}, SD = {nback_wide['acc_1back'].std():.3f}\")\n",
    "print(f\"2-back accuracy: M = {nback_wide['acc_2back'].mean():.3f}, SD = {nback_wide['acc_2back'].std():.3f}\")\n",
    "\n",
    "# Shapiro-Wilk on difference scores\n",
    "w_stat, p_val = shapiro(nback_wide[\"diff\"])\n",
    "print(f\"\\nShapiro-Wilk on differences: W = {w_stat:.3f}, p = {p_val:.4f}\")\n",
    "\n",
    "# Wilcoxon (primary \u2014 normality likely violated)\n",
    "wx_stat, wx_p = wilcoxon(nback_wide[\"acc_1back\"], nback_wide[\"acc_2back\"], alternative=\"greater\")\n",
    "print(f\"\\nWilcoxon (one-tailed, 1-back > 2-back): W = {wx_stat}, p = {wx_p:.4g}\")\n",
    "\n",
    "# Paired t-test (confirmatory)\n",
    "t_result = pg.ttest(nback_wide[\"acc_1back\"], nback_wide[\"acc_2back\"], paired=True, alternative=\"greater\")\n",
    "print(f\"Paired t-test: t({t_result['dof'].values[0]}) = {t_result['T'].values[0]:.2f}, \"\n",
    "      f\"p = {t_result['p_val'].values[0]:.4g}, d = {t_result['cohen_d'].values[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:43.877013Z",
     "iopub.status.busy": "2026-02-28T18:25:43.876939Z",
     "iopub.status.idle": "2026-02-28T18:25:44.008188Z",
     "shell.execute_reply": "2026-02-28T18:25:44.007761Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "nback_wide_sorted = nback_wide.sort_values('diff', ascending=True).reset_index()\n",
    "\n",
    "y_pos = np.arange(len(nback_wide_sorted))\n",
    "\n",
    "for i, row in nback_wide_sorted.iterrows():\n",
    "    ax.plot([row['acc_1back'], row['acc_2back']], [i, i],\n",
    "            color='#CCCCCC', linewidth=1.5, zorder=1)\n",
    "    ax.scatter(row['acc_1back'], i, color=COLORS['teal'], s=60,\n",
    "               zorder=2, edgecolor=COLORS['primary_dark'], linewidth=0.5)\n",
    "    ax.scatter(row['acc_2back'], i, color=COLORS['pink'], s=60,\n",
    "               zorder=2, edgecolor=COLORS['primary_dark'], linewidth=0.5)\n",
    "\n",
    "mean_1back = nback_wide['acc_1back'].mean()\n",
    "mean_2back = nback_wide['acc_2back'].mean()\n",
    "\n",
    "ax.axvline(mean_1back, color=COLORS['teal'], linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax.axvline(mean_2back, color=COLORS['pink'], linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "ax.set_xlabel('N-back Accuracy', fontsize=12, color=COLORS['primary_dark'])\n",
    "ax.set_ylabel('Participants (sorted by effect)', fontsize=12, color=COLORS['primary_dark'])\n",
    "ax.set_title('N-back Accuracy: 1-back vs. 2-back',\n",
    "             fontsize=14, fontweight='bold', color=COLORS['primary_dark'])\n",
    "ax.set_xlim(0.94, 1.005)\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax.xaxis.grid(True, alpha=0.2, linestyle='--', color=COLORS['primary_dark'])\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor=COLORS['teal'],\n",
    "           markersize=8, label=f'1-back: M={mean_1back:.3f}'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor=COLORS['pink'],\n",
    "           markersize=8, label=f'2-back: M={mean_2back:.3f}')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower left', frameon=True, fontsize=10)\n",
    "\n",
    "# Compute effect size\n",
    "pooled_sd = np.sqrt((nback_wide['acc_1back'].std()**2 + nback_wide['acc_2back'].std()**2) / 2)\n",
    "effect_size_d = (mean_1back - mean_2back) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "effect_text = (f'Wilcoxon W = 286.0\\n'\n",
    "               f'p < .001\\n'\n",
    "               f\"Cohen\\'s d = {effect_size_d:.3f}\")\n",
    "ax.text(0.2, 0.98, effect_text,\n",
    "        transform=ax.transAxes,\n",
    "        ha='right', va='top', fontsize=10,\n",
    "        bbox=dict(boxstyle='round,pad=0.5',\n",
    "                  facecolor=COLORS['white'],\n",
    "                  edgecolor=COLORS['primary_dark'],\n",
    "                  alpha=0.9))\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.009379Z",
     "iopub.status.busy": "2026-02-28T18:25:44.009302Z",
     "iopub.status.idle": "2026-02-28T18:25:44.043596Z",
     "shell.execute_reply": "2026-02-28T18:25:44.043237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate: per-participant variance and CV of time estimates by condition\n",
    "timing_props = df_clean.groupby(GROUP_COLS, as_index=False).agg(\n",
    "    mean_duration=(\"OUT_actual_trial_duration_sec\", \"mean\"),\n",
    "    var_estimate=(\"OUT_time_estimate_seconds\", \"var\"),\n",
    "    cv_estimate=(\"OUT_time_estimate_seconds\", coefficient_of_variation),\n",
    "    mean_estimate=(\"OUT_time_estimate_seconds\", \"mean\"),\n",
    ")\n",
    "\n",
    "# Log-transform to address heteroscedasticity\n",
    "timing_props[\"log_var\"] = np.log(timing_props[\"var_estimate\"].clip(lower=1e-10))\n",
    "timing_props[\"log_cv\"] = np.log(timing_props[\"cv_estimate\"].clip(lower=1e-10))\n",
    "\n",
    "# LMM 1: log(variance) ~ mean_duration\n",
    "print(\"=== LMM: log(Variance) ~ Mean Duration ===\")\n",
    "md_var = smf.mixedlm(\"log_var ~ mean_duration\",\n",
    "                      data=timing_props, groups=timing_props[\"participant_id\"]).fit()\n",
    "print(md_var.summary().tables[1])\n",
    "\n",
    "# LMM 2: log(CV) ~ mean_duration\n",
    "print(\"\\n=== LMM: log(CV) ~ Mean Duration ===\")\n",
    "md_cv = smf.mixedlm(\"log_cv ~ mean_duration\",\n",
    "                     data=timing_props, groups=timing_props[\"participant_id\"]).fit()\n",
    "print(md_cv.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.044870Z",
     "iopub.status.busy": "2026-02-28T18:25:44.044786Z",
     "iopub.status.idle": "2026-02-28T18:25:44.184355Z",
     "shell.execute_reply": "2026-02-28T18:25:44.183790Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# LEFT: Absolute variance increases\n",
    "sns.regplot(data=df_clean, x='OUT_actual_trial_duration_sec', y='OUT_time_estimate_seconds',\n",
    "            scatter_kws={'alpha': 0.1, 'color': '#1f77b4'},\n",
    "            line_kws={'color': '#ff7f0e', 'linewidth': 3}, ax=ax1)\n",
    "ax1.set_title(\"Weber's Law (1): Absolute Variance Increases\", fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Trial Duration (s)', fontsize=12)\n",
    "ax1.set_ylabel('Estimated Trial Duration (s)', fontsize=12)\n",
    "ax1.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "# RIGHT: CV remains constant\n",
    "ax2.scatter(timing_props['mean_duration'], timing_props['cv_estimate'],\n",
    "            alpha=0.4, color='#1f77b4', s=20)\n",
    "ax2.axhline(y=timing_props['cv_estimate'].mean(), color='#ff7f0e',\n",
    "            linestyle='--', linewidth=3,\n",
    "            label=f'Mean CV = {timing_props[\"cv_estimate\"].mean():.3f}')\n",
    "ax2.set_title(\"Weber's Law (2): Proportional Variability Remains Constant\", fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Trial Duration (s)', fontsize=12)\n",
    "ax2.set_ylabel('Coefficient of Variation (\u03c3/\u03bc) of Estimates', fontsize=12)\n",
    "ax2.legend(loc='upper right', frameon=True)\n",
    "ax2.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "ax2.set_ylim(0, 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Tendency Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.186348Z",
     "iopub.status.busy": "2026-02-28T18:25:44.186255Z",
     "iopub.status.idle": "2026-02-28T18:25:44.219426Z",
     "shell.execute_reply": "2026-02-28T18:25:44.219105Z"
    }
   },
   "outputs": [],
   "source": [
    "# Signed estimation error (subjective - objective)\n",
    "df_clean[\"estimation_error\"] = (\n",
    "    df_clean[\"OUT_time_estimate_seconds\"] - df_clean[\"OUT_actual_trial_duration_sec\"]\n",
    ")\n",
    "df_clean[\"log_SO_ratio\"] = np.log(df_clean[\"OUT_time_estimation_ratio\"].clip(lower=1e-10))\n",
    "\n",
    "# LMM: estimation_error ~ trial_duration\n",
    "print(\"=== LMM: Estimation Error ~ Trial Duration ===\")\n",
    "md_vierordt = smf.mixedlm(\n",
    "    \"estimation_error ~ OUT_actual_trial_duration_sec\",\n",
    "    data=df_clean, groups=df_clean[\"participant_id\"]\n",
    ").fit()\n",
    "print(md_vierordt.summary().tables[1])\n",
    "\n",
    "# Indifference point\n",
    "intercept = md_vierordt.fe_params[\"Intercept\"]\n",
    "slope = md_vierordt.fe_params[\"OUT_actual_trial_duration_sec\"]\n",
    "indifference = -intercept / slope\n",
    "print(f\"\\nIndifference point: {indifference:.2f} s\")\n",
    "\n",
    "# Log-transformed model\n",
    "print(\"\\n=== LMM: log(SO_ratio) ~ Trial Duration ===\")\n",
    "md_log = smf.mixedlm(\n",
    "    \"log_SO_ratio ~ OUT_actual_trial_duration_sec\",\n",
    "    data=df_clean, groups=df_clean[\"participant_id\"]\n",
    ").fit()\n",
    "print(md_log.summary().tables[1])\n",
    "\n",
    "intercept_log = md_log.fe_params[\"Intercept\"]\n",
    "slope_log = md_log.fe_params[\"OUT_actual_trial_duration_sec\"]\n",
    "indifference_log = -intercept_log / slope_log\n",
    "print(f\"Indifference point (log model): {indifference_log:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.220727Z",
     "iopub.status.busy": "2026-02-28T18:25:44.220650Z",
     "iopub.status.idle": "2026-02-28T18:25:44.403793Z",
     "shell.execute_reply": "2026-02-28T18:25:44.403402Z"
    }
   },
   "outputs": [],
   "source": [
    "df_v = df_clean.copy()\n",
    "df_v[\"err_sec\"] = df_v[\"OUT_time_estimate_seconds\"] - df_v[\"OUT_actual_trial_duration_sec\"]\n",
    "grand_mean_dur = df_v[\"OUT_actual_trial_duration_sec\"].mean()\n",
    "df_v[\"dur_c\"] = df_v[\"OUT_actual_trial_duration_sec\"] - grand_mean_dur\n",
    "\n",
    "df_v[\"so_ratio\"] = df_v[\"OUT_time_estimate_seconds\"] / (df_v[\"OUT_actual_trial_duration_sec\"] + 1e-9)\n",
    "df_v[\"log_so_ratio\"] = np.log(df_v[\"so_ratio\"] + 1e-9)\n",
    "\n",
    "model1 = smf.mixedlm(\"err_sec ~ dur_c\", df_v, groups=\"participant_id\",\n",
    "                      re_formula=\"~dur_c\").fit(method=\"lbfgs\")\n",
    "print(model1.summary())\n",
    "\n",
    "model2 = smf.mixedlm(\"log_so_ratio ~ dur_c\", df_v, groups=\"participant_id\",\n",
    "                      re_formula=\"~dur_c\").fit(method=\"lbfgs\")\n",
    "print(model2.summary())\n",
    "\n",
    "b0_1, b1_1 = model1.params[\"Intercept\"], model1.params[\"dur_c\"]\n",
    "indiff_1 = -b0_1 / b1_1 + grand_mean_dur\n",
    "print(f\"\\nModel 1 Indifference point: {indiff_1:.2f} s\")\n",
    "\n",
    "b0_2, b1_2 = model2.params[\"Intercept\"], model2.params[\"dur_c\"]\n",
    "indiff_2 = -b0_2 / b1_2 + grand_mean_dur\n",
    "print(f\"Model 2 Indifference point: {indiff_2:.2f} s\")\n",
    "\n",
    "sns.set(style=\"white\", context=\"notebook\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "sns.scatterplot(data=df_v, x=\"OUT_actual_trial_duration_sec\", y=\"err_sec\",\n",
    "                alpha=.15, linewidth=0, edgecolor=None, ax=ax1)\n",
    "x1 = np.linspace(df_v[\"OUT_actual_trial_duration_sec\"].min(),\n",
    "                 df_v[\"OUT_actual_trial_duration_sec\"].max(), 200)\n",
    "y1 = b0_1 + b1_1 * (x1 - grand_mean_dur)\n",
    "ax1.plot(x1, y1, color=\"black\", lw=2, label=\"Mixed-model fit\")\n",
    "ax1.axhline(0, ls=\"--\", c=\"grey\", lw=1)\n",
    "ax1.plot([], [], ' ', label=f\"Indiff. point: {indiff_1:.2f}s\")\n",
    "ax1.set_xlabel(\"Actual trial duration (s)\")\n",
    "ax1.set_ylabel(\"Signed estimation error (s)\")\n",
    "ax1.set_title(\"Vierordt's Law: Signed Error Approach\")\n",
    "ax1.legend(frameon=False, loc='upper right')\n",
    "\n",
    "ax2 = axes[1]\n",
    "sns.scatterplot(data=df_v, x=\"OUT_actual_trial_duration_sec\", y=\"log_so_ratio\",\n",
    "                alpha=.15, linewidth=0, edgecolor=None, ax=ax2)\n",
    "x2 = np.linspace(df_v[\"OUT_actual_trial_duration_sec\"].min(),\n",
    "                 df_v[\"OUT_actual_trial_duration_sec\"].max(), 200)\n",
    "y2 = b0_2 + b1_2 * (x2 - grand_mean_dur)\n",
    "ax2.plot(x2, y2, color=\"black\", lw=2, label=\"Mixed-model fit\")\n",
    "ax2.axhline(0, ls=\"--\", c=\"grey\", lw=1)\n",
    "ax2.plot([], [], ' ', label=f\"Indiff. point: {indiff_2:.2f}s\")\n",
    "ax2.set_xlabel(\"Actual Trial Duration (s)\")\n",
    "ax2.set_ylabel(\"Log (Subjective / Objective Ratio)\")\n",
    "ax2.set_title(\"Vierordt's Law: Log S/O Ratio Approach\")\n",
    "ax2.legend(frameon=False, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.404946Z",
     "iopub.status.busy": "2026-02-28T18:25:44.404854Z",
     "iopub.status.idle": "2026-02-28T18:25:44.489860Z",
     "shell.execute_reply": "2026-02-28T18:25:44.489382Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "x = df_clean['OUT_actual_trial_duration_sec'].values\n",
    "y = df_clean['OUT_time_estimate_seconds'].values\n",
    "\n",
    "ax.scatter(x, y, alpha=0.05, s=8, color='gray', zorder=1)\n",
    "\n",
    "n_bins = 20\n",
    "bin_edges = np.percentile(x, np.linspace(0, 100, n_bins + 1))\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "means = []\n",
    "sds = []\n",
    "for i in range(n_bins):\n",
    "    mask = (x >= bin_edges[i]) & (x < bin_edges[i + 1])\n",
    "    if mask.sum() > 2:\n",
    "        means.append(y[mask].mean())\n",
    "        sds.append(y[mask].std())\n",
    "    else:\n",
    "        means.append(np.nan)\n",
    "        sds.append(np.nan)\n",
    "\n",
    "valid = ~np.isnan(means)\n",
    "bin_centers = bin_centers[valid]\n",
    "means = np.array(means)[valid]\n",
    "sds = np.array(sds)[valid]\n",
    "\n",
    "z = np.polyfit(bin_centers, means, 2)\n",
    "p_mean = np.poly1d(z)\n",
    "z_sd = np.polyfit(bin_centers, sds, 1)\n",
    "p_sd = np.poly1d(z_sd)\n",
    "\n",
    "x_smooth = np.linspace(10, 35, 100)\n",
    "y_mean = p_mean(x_smooth)\n",
    "y_sd = p_sd(x_smooth)\n",
    "\n",
    "ax.plot(x_smooth, y_mean, color=COLORS['primary_dark'], linewidth=3, zorder=3)\n",
    "\n",
    "ax.fill_between(x_smooth, y_mean - y_sd, y_mean + y_sd,\n",
    "                color=COLORS['teal'], alpha=0.2, zorder=2)\n",
    "ax.plot(x_smooth, y_mean + y_sd, color=COLORS['teal'], linewidth=1.5,\n",
    "        linestyle='--', alpha=0.7, zorder=2)\n",
    "ax.plot(x_smooth, y_mean - y_sd, color=COLORS['teal'], linewidth=1.5,\n",
    "        linestyle='--', alpha=0.7, zorder=2)\n",
    "\n",
    "ax.fill_between(x_smooth, y_mean - 2*y_sd, y_mean + 2*y_sd,\n",
    "                color=COLORS['pink'], alpha=0.1, zorder=1)\n",
    "ax.plot(x_smooth, y_mean + 2*y_sd, color=COLORS['pink'], linewidth=1,\n",
    "        linestyle=':', alpha=0.5, zorder=2)\n",
    "ax.plot(x_smooth, y_mean - 2*y_sd, color=COLORS['pink'], linewidth=1,\n",
    "        linestyle=':', alpha=0.5, zorder=2)\n",
    "\n",
    "ax.plot([10, 35], [10, 35], 'k--', alpha=0.4, linewidth=1.5, zorder=2)\n",
    "\n",
    "indiff_x = indifference\n",
    "indiff_y = p_mean(indiff_x)\n",
    "ax.scatter([indiff_x], [indiff_y], color='orange', s=100, marker='o', zorder=5, linewidth=1)\n",
    "\n",
    "ax.annotate('Overestimation\\nregion', xy=(16, 17), xytext=(13, 20),\n",
    "            fontsize=11, ha='center', color=COLORS['primary_dark'])\n",
    "ax.annotate('Underestimation\\nregion', xy=(27, 26), xytext=(31, 23),\n",
    "            fontsize=11, ha='center', color=COLORS['primary_dark'])\n",
    "\n",
    "ax.set_xlabel('Actual Trial Duration (seconds)', fontsize=13, color=COLORS['primary_dark'])\n",
    "ax.set_ylabel('Estimated Duration (seconds)', fontsize=13, color=COLORS['primary_dark'])\n",
    "ax.set_title('Demonstration of Psychophysical Timing Properties in the Study',\n",
    "             fontsize=14, fontweight='bold', color=COLORS['primary_dark'])\n",
    "ax.set_xlim(10, 35)\n",
    "ax.set_ylim(10, 35)\n",
    "\n",
    "ax.grid(True, alpha=0.15, linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='gray',\n",
    "           markersize=6, alpha=0.5, label='Individual estimates', linestyle='None'),\n",
    "    Line2D([0], [0], color=COLORS['primary_dark'], linewidth=3,\n",
    "           label='Mean estimate'),\n",
    "    Line2D([0], [0], color='w', markerfacecolor=COLORS['teal'], alpha=0.3,\n",
    "           marker='s', markersize=10, label='\\u00b11 SD', linestyle='None'),\n",
    "    Line2D([0], [0], color='w', markerfacecolor=COLORS['pink'], alpha=0.2,\n",
    "           marker='s', markersize=10, label='\\u00b12 SD', linestyle='None'),\n",
    "    Line2D([0], [0], color='black', linewidth=1.5, linestyle='--',\n",
    "           alpha=0.4, label='Perfect estimation'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='orange',\n",
    "           markersize=8, label=f'Indifference point ({indiff_x:.1f}s)', linestyle='None')\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=legend_elements, loc='upper left', frameon=True,\n",
    "                   fontsize=10, fancybox=False, edgecolor=COLORS['primary_dark'])\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "interpretation = (\"Weber\\'s Law: Bands expand linearly \\u2192 Constant CV\\n\"\n",
    "                  \"Vierordt\\'s Law: Mean crosses diagonal \\u2192 Central tendency\")\n",
    "ax.text(0.98, 0.02, interpretation, transform=ax.transAxes, fontsize=10,\n",
    "        ha='right', va='bottom', style='italic',\n",
    "        bbox=dict(boxstyle='round', facecolor='white',\n",
    "                  edgecolor=COLORS['primary_dark'], alpha=0.9))\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Perception: 2\\u00d72 Repeated-Measures ANOVAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.491200Z",
     "iopub.status.busy": "2026-02-28T18:25:44.491116Z",
     "iopub.status.idle": "2026-02-28T18:25:44.506411Z",
     "shell.execute_reply": "2026-02-28T18:25:44.506122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate time perception at participant x condition level\n",
    "agg_tp = df_clean.groupby(GROUP_COLS, as_index=False).agg(\n",
    "    mean_abs_error=(\"OUT_normalized_absolute_error\", \"mean\"),\n",
    "    mean_SO_ratio=(\"OUT_time_estimation_ratio\", \"mean\"),\n",
    "    cv_estimate=(\"OUT_time_estimate_seconds\", coefficient_of_variation),\n",
    ")\n",
    "\n",
    "tp_dvs = [\"mean_abs_error\", \"mean_SO_ratio\", \"cv_estimate\"]\n",
    "\n",
    "# Cell-level outlier screening (per-cell z > 3.29)\n",
    "for dv in tp_dvs:\n",
    "    agg_tp[\"_outlier_uni\"] = False\n",
    "    for _, grp in agg_tp.groupby([\"COND_interruption_condition\", \"COND_nback_level\"]):\n",
    "        z = zscore(grp[dv], nan_policy=\"omit\")\n",
    "        mask = np.abs(z) > 3.29\n",
    "        agg_tp.loc[grp.index, \"_outlier_uni\"] = mask\n",
    "    n_uni = agg_tp[\"_outlier_uni\"].sum()\n",
    "    if n_uni > 0:\n",
    "        for idx in agg_tp.index[agg_tp[\"_outlier_uni\"]]:\n",
    "            row = agg_tp.loc[idx]\n",
    "            cell_mask = (\n",
    "                (agg_tp[\"COND_interruption_condition\"] == row[\"COND_interruption_condition\"])\n",
    "                & (agg_tp[\"COND_nback_level\"] == row[\"COND_nback_level\"])\n",
    "                & (agg_tp.index != idx)\n",
    "            )\n",
    "            agg_tp.loc[idx, dv] = agg_tp.loc[cell_mask, dv].median()\n",
    "        print(f\"{dv}: {n_uni} univariate outlier(s) winsorised (per-cell z > 3.29).\")\n",
    "    else:\n",
    "        print(f\"{dv}: no univariate outliers.\")\n",
    "    agg_tp.drop(columns=[\"_outlier_uni\"], inplace=True)\n",
    "\n",
    "# Multivariate: Mahalanobis on 4-cell vectors per participant per DV\n",
    "for dv in tp_dvs:\n",
    "    wide = (\n",
    "        agg_tp.pivot(index=\"participant_id\",\n",
    "                     columns=[\"COND_interruption_condition\", \"COND_nback_level\"],\n",
    "                     values=dv)\n",
    "        .dropna()\n",
    "    )\n",
    "    X = wide.values\n",
    "    mean = X.mean(axis=0)\n",
    "    cov = np.cov(X.T)\n",
    "    if np.linalg.det(cov) == 0:\n",
    "        print(f\"{dv}: covariance matrix is singular; skipping multivariate check.\")\n",
    "        continue\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    diff = X - mean\n",
    "    md = np.sqrt(np.sum(diff @ cov_inv * diff, axis=1))\n",
    "    cutoff = np.sqrt(chi2.ppf(1 - 0.001, df=wide.shape[1]))\n",
    "    multi_flags = md > cutoff\n",
    "    n_multi = multi_flags.sum()\n",
    "    if n_multi > 0:\n",
    "        outlier_pids = wide.index[multi_flags]\n",
    "        for pid in outlier_pids:\n",
    "            pid_mask = agg_tp[\"participant_id\"] == pid\n",
    "            cell_median = agg_tp.loc[~pid_mask, dv].median()\n",
    "            agg_tp.loc[pid_mask, dv] = cell_median\n",
    "        print(f\"{dv}: {n_multi} multivariate outlier(s) winsorised.\")\n",
    "    else:\n",
    "        print(f\"{dv}: no multivariate outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.507703Z",
     "iopub.status.busy": "2026-02-28T18:25:44.507629Z",
     "iopub.status.idle": "2026-02-28T18:25:44.645617Z",
     "shell.execute_reply": "2026-02-28T18:25:44.645225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normality checks\n",
    "for dv in tp_dvs:\n",
    "    normality_check(agg_tp, dv, WITHIN, SUBJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.646908Z",
     "iopub.status.busy": "2026-02-28T18:25:44.646823Z",
     "iopub.status.idle": "2026-02-28T18:25:44.653593Z",
     "shell.execute_reply": "2026-02-28T18:25:44.653147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Variance equality\n",
    "# Create condition label for grouping\n",
    "if \"condition_label\" not in agg_tp.columns:\n",
    "    agg_tp[\"condition_label\"] = agg_tp.apply(create_condition_label, axis=1)\n",
    "\n",
    "for dv in tp_dvs:\n",
    "    variance_equality_tests(agg_tp, dv, \"condition_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.654640Z",
     "iopub.status.busy": "2026-02-28T18:25:44.654568Z",
     "iopub.status.idle": "2026-02-28T18:25:44.689799Z",
     "shell.execute_reply": "2026-02-28T18:25:44.689388Z"
    }
   },
   "outputs": [],
   "source": [
    "report_rm_anova(agg_tp, \"mean_abs_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.690809Z",
     "iopub.status.busy": "2026-02-28T18:25:44.690738Z",
     "iopub.status.idle": "2026-02-28T18:25:44.796661Z",
     "shell.execute_reply": "2026-02-28T18:25:44.794915Z"
    }
   },
   "outputs": [],
   "source": [
    "report_rm_anova(agg_tp, \"mean_SO_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.800828Z",
     "iopub.status.busy": "2026-02-28T18:25:44.800549Z",
     "iopub.status.idle": "2026-02-28T18:25:44.876748Z",
     "shell.execute_reply": "2026-02-28T18:25:44.875470Z"
    }
   },
   "outputs": [],
   "source": [
    "report_rm_anova(agg_tp, \"cv_estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.880842Z",
     "iopub.status.busy": "2026-02-28T18:25:44.880512Z",
     "iopub.status.idle": "2026-02-28T18:25:44.937946Z",
     "shell.execute_reply": "2026-02-28T18:25:44.935840Z"
    }
   },
   "outputs": [],
   "source": [
    "# ART ANOVA for CV (normality violated)\n",
    "art_anova(agg_tp, \"cv_estimate\", WITHIN, SUBJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:44.942353Z",
     "iopub.status.busy": "2026-02-28T18:25:44.942106Z",
     "iopub.status.idle": "2026-02-28T18:25:45.366487Z",
     "shell.execute_reply": "2026-02-28T18:25:45.365376Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, dv, ylabel, title in [\n",
    "    (axes[0], \"mean_abs_error\", \"Absolute Error\", \"Absolute Error\"),\n",
    "    (axes[1], \"mean_SO_ratio\", \"S/O Ratio\", \"S/O Ratio\"),\n",
    "    (axes[2], \"cv_estimate\", \"Coefficient of Variation\", \"CV\"),\n",
    "]:\n",
    "    sns.pointplot(\n",
    "        data=agg_tp, x=\"COND_nback_level\", y=dv,\n",
    "        hue=\"COND_interruption_condition\",\n",
    "        dodge=0.2, markers=[\"o\", \"s\"], linestyles=[\"-\", \"--\"],\n",
    "        palette={\"sequential\": COLORS[\"teal_dark\"], \"interrupted\": COLORS[\"pink_dark\"]},\n",
    "        capsize=0.1, err_kws={\"linewidth\": 2}, ax=ax, legend=False,\n",
    "    )\n",
    "    ax.set_xlabel(\"Task Complexity\", fontsize=11)\n",
    "    ax.set_ylabel(ylabel, fontsize=11)\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels([\"1-back\\n(Easy)\", \"2-back\\n(Hard)\"])\n",
    "    ax.yaxis.grid(True, alpha=0.15, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    if dv == \"mean_SO_ratio\":\n",
    "        ax.axhline(y=1.0, color=COLORS[\"primary_dark\"], linestyle=\":\", alpha=0.3)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=COLORS[\"teal_dark\"], linestyle=\"-\", marker=\"o\", markersize=6, label=\"Sequential\"),\n",
    "    Line2D([0], [0], color=COLORS[\"pink_dark\"], linestyle=\"--\", marker=\"s\", markersize=6, label=\"Interrupted\"),\n",
    "]\n",
    "fig.legend(handles=legend_elements, title=\"Condition\", loc=\"upper right\",\n",
    "           bbox_to_anchor=(0.98, 0.98), frameon=True, fontsize=9, title_fontsize=10)\n",
    "fig.suptitle(\"Time Perception: Interaction Plots\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:45.368767Z",
     "iopub.status.busy": "2026-02-28T18:25:45.368632Z",
     "iopub.status.idle": "2026-02-28T18:25:45.428167Z",
     "shell.execute_reply": "2026-02-28T18:25:45.427773Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "abs_wide = (agg_tp.groupby(['participant_id', 'COND_interruption_condition'])\n",
    "            .agg({'mean_abs_error': 'mean'})\n",
    "            .unstack('COND_interruption_condition')\n",
    "            .droplevel(0, axis=1))\n",
    "\n",
    "data_seq = abs_wide['sequential'].values\n",
    "data_int = abs_wide['interrupted'].values\n",
    "\n",
    "np.random.seed(42)\n",
    "x_seq = np.ones(len(data_seq)) + np.random.normal(0, 0.02, len(data_seq))\n",
    "x_int = 2 * np.ones(len(data_int)) + np.random.normal(0, 0.02, len(data_int))\n",
    "\n",
    "ax.scatter(x_seq, data_seq, color=COLORS['teal'], alpha=0.6, s=50,\n",
    "           edgecolor=COLORS['primary_dark'], linewidth=0.5)\n",
    "ax.scatter(x_int, data_int, color=COLORS['pink'], alpha=0.6, s=50,\n",
    "           edgecolor=COLORS['primary_dark'], linewidth=0.5)\n",
    "\n",
    "for i in range(len(data_seq)):\n",
    "    ax.plot([x_seq[i], x_int[i]], [data_seq[i], data_int[i]],\n",
    "            color='gray', alpha=0.15, linewidth=0.5, zorder=0)\n",
    "\n",
    "mean_seq = data_seq.mean()\n",
    "mean_int = data_int.mean()\n",
    "sem_seq = data_seq.std() / np.sqrt(len(data_seq))\n",
    "sem_int = data_int.std() / np.sqrt(len(data_int))\n",
    "\n",
    "ax.errorbar([1], [mean_seq], yerr=[sem_seq], color=COLORS['teal_dark'],\n",
    "            linewidth=3, capsize=8, capthick=3, zorder=10)\n",
    "ax.errorbar([2], [mean_int], yerr=[sem_int], color=COLORS['pink_dark'],\n",
    "            linewidth=3, capsize=8, capthick=3, zorder=10)\n",
    "\n",
    "ax.plot([1, 2], [mean_seq, mean_int], 'k-', linewidth=2, zorder=9)\n",
    "\n",
    "ax.scatter([1], [mean_seq], color=COLORS['teal_dark'], s=200,\n",
    "           edgecolor='white', linewidth=2, zorder=11)\n",
    "ax.scatter([2], [mean_int], color=COLORS['pink_dark'], s=200,\n",
    "           edgecolor='white', linewidth=2, zorder=11)\n",
    "\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels(['Sequential', 'Interrupted'], fontsize=12)\n",
    "ax.set_ylabel('Absolute Error', fontsize=12)\n",
    "ax.set_title('Absolute Error of Time Estimates by Interruption Condition',\n",
    "             fontsize=10, fontweight='bold')\n",
    "ax.set_xlim(0.5, 2.5)\n",
    "ax.set_ylim(0.02, 0.25)\n",
    "\n",
    "diff = mean_int - mean_seq\n",
    "ax.annotate('', xy=(2.3, mean_int), xytext=(2.3, mean_seq),\n",
    "            arrowprops=dict(arrowstyle='<->', color=COLORS['primary_dark'], lw=1.5))\n",
    "ax.text(2.35, (mean_seq + mean_int)/2, f'p = .069\\n\u03b7\u00b2g = .013',\n",
    "        fontsize=10, va='center')\n",
    "\n",
    "ax.yaxis.grid(True, alpha=0.2, linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:45.430170Z",
     "iopub.status.busy": "2026-02-28T18:25:45.430006Z",
     "iopub.status.idle": "2026-02-28T18:25:45.629974Z",
     "shell.execute_reply": "2026-02-28T18:25:45.625355Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, metric_col, y_label, title, hline_val, ylims in [\n",
    "    (axes[0], 'OUT_normalized_absolute_error', 'Normalized Absolute Error',\n",
    "     'Timing Accuracy by Interruption Condition', 0.0, (-0.1, 0.8)),\n",
    "    (axes[1], 'OUT_time_estimation_ratio', 'Subjective / Objective Ratio',\n",
    "     'Time Estimation Bias by Interruption Condition', 1.0, (0.2, 1.8)),\n",
    "]:\n",
    "    sns.boxplot(x='COND_interruption_condition', y=metric_col, data=df_clean,\n",
    "                ax=ax, palette=CONDITION_COLORS, width=0.4, fliersize=0)\n",
    "    sns.stripplot(x='COND_interruption_condition', y=metric_col, data=df_clean,\n",
    "                  ax=ax, jitter=0.1, color=\".25\", alpha=0.3, s=4)\n",
    "    ax.axhline(hline_val, color='black', linestyle='--', linewidth=1.5, alpha=0.6)\n",
    "    ax.set_title(title, fontsize=14, pad=15)\n",
    "    ax.set_xlabel('Condition', fontsize=12)\n",
    "    ax.set_ylabel(y_label, fontsize=12)\n",
    "    ax.set_ylim(*ylims)\n",
    "    ax.set_xticklabels([l.get_text().capitalize() for l in ax.get_xticklabels()])\n",
    "    sns.despine(ax=ax, trim=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation: Performance and Time Perception Disruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:45.638198Z",
     "iopub.status.busy": "2026-02-28T18:25:45.637957Z",
     "iopub.status.idle": "2026-02-28T18:25:45.658240Z",
     "shell.execute_reply": "2026-02-28T18:25:45.653729Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute delta scores per participant\n",
    "perf_by_int = (\n",
    "    df_clean.groupby([\"participant_id\", \"COND_interruption_condition\"])\n",
    "    .agg(\n",
    "        mean_tpl=(\"OUT_time_per_letter\", \"mean\"),\n",
    "        mean_ae=(\"OUT_normalized_absolute_error\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "delta_wide = perf_by_int.pivot(index=\"participant_id\", columns=\"COND_interruption_condition\",\n",
    "                                values=[\"mean_tpl\", \"mean_ae\"])\n",
    "delta_wide.columns = [\"_\".join(c) for c in delta_wide.columns]\n",
    "delta_wide = delta_wide.reset_index()\n",
    "\n",
    "delta_wide[\"delta_tpl\"] = delta_wide[\"mean_tpl_interrupted\"] - delta_wide[\"mean_tpl_sequential\"]\n",
    "delta_wide[\"delta_ae\"] = delta_wide[\"mean_ae_interrupted\"] - delta_wide[\"mean_ae_sequential\"]\n",
    "\n",
    "print(f\"N = {len(delta_wide)} participants\")\n",
    "print(f\"Delta time_per_letter: M = {delta_wide['delta_tpl'].mean():.3f}, SD = {delta_wide['delta_tpl'].std():.3f}\")\n",
    "print(f\"Delta absolute_error:  M = {delta_wide['delta_ae'].mean():.3f}, SD = {delta_wide['delta_ae'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:45.665667Z",
     "iopub.status.busy": "2026-02-28T18:25:45.665210Z",
     "iopub.status.idle": "2026-02-28T18:25:45.705072Z",
     "shell.execute_reply": "2026-02-28T18:25:45.678590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Homoscedasticity: Breusch-Pagan\n",
    "X = sm.add_constant(delta_wide[\"delta_tpl\"])\n",
    "model = sm.OLS(delta_wide[\"delta_ae\"], X).fit()\n",
    "bp_stat, bp_p, _, _ = het_breuschpagan(model.resid, X)\n",
    "print(f\"Breusch-Pagan: chi2(1) = {bp_stat:.2f}, p = {bp_p:.3f}\")\n",
    "\n",
    "# Normality\n",
    "for col, label in [(\"delta_tpl\", \"delta_time_per_letter\"), (\"delta_ae\", \"delta_absolute_error\")]:\n",
    "    w, p = shapiro(delta_wide[col])\n",
    "    print(f\"Shapiro-Wilk ({label}): W = {w:.3f}, p = {p:.4f}\")\n",
    "\n",
    "# Bivariate normality: Henze-Zirkler\n",
    "hz = pg.multivariate_normality(\n",
    "    delta_wide[[\"delta_tpl\", \"delta_ae\"]], alpha=ALPHA\n",
    ")\n",
    "print(f\"\\nHenze-Zirkler: HZ = {hz.hz:.2f}, p = {hz.pval:.4f}, normal = {hz.normal}\")\n",
    "\n",
    "# Outlier detection\n",
    "# IQR-based\n",
    "for col in [\"delta_tpl\", \"delta_ae\"]:\n",
    "    flags = flag_outliers_iqr(delta_wide[col], k=2.5)\n",
    "    print(f\"IQR outliers ({col}): {flags.sum()}\")\n",
    "\n",
    "# Mahalanobis\n",
    "md, md_p = mahalanobis_distances(delta_wide, [\"delta_tpl\", \"delta_ae\"])\n",
    "multi_outliers = md_p < 0.01\n",
    "print(f\"Multivariate outliers (Mahalanobis, alpha=.01): {multi_outliers.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:45.712231Z",
     "iopub.status.busy": "2026-02-28T18:25:45.711733Z",
     "iopub.status.idle": "2026-02-28T18:25:45.718617Z",
     "shell.execute_reply": "2026-02-28T18:25:45.717333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pearson correlation (full sample)\n",
    "r, p = stats.pearsonr(delta_wide[\"delta_tpl\"], delta_wide[\"delta_ae\"])\n",
    "n = len(delta_wide)\n",
    "print(f\"Full sample (N = {n}):\")\n",
    "print(f\"  Pearson r({n-2}) = {r:.2f}, p = {p:.3f}\")\n",
    "\n",
    "# Bayes Factor\n",
    "bf = pg.bayesfactor_pearson(r, n)\n",
    "print(f\"  BF10 = {bf:.2f}\")\n",
    "\n",
    "# Without outliers\n",
    "delta_clean = delta_wide[~multi_outliers].copy()\n",
    "r2, p2 = stats.pearsonr(delta_clean[\"delta_tpl\"], delta_clean[\"delta_ae\"])\n",
    "n2 = len(delta_clean)\n",
    "bf2 = pg.bayesfactor_pearson(r2, n2)\n",
    "print(f\"\\nWithout outliers (N = {n2}):\")\n",
    "print(f\"  Pearson r({n2-2}) = {r2:.2f}, p = {p2:.3f}\")\n",
    "print(f\"  BF10 = {bf2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:45.721257Z",
     "iopub.status.busy": "2026-02-28T18:25:45.721124Z",
     "iopub.status.idle": "2026-02-28T18:25:45.779728Z",
     "shell.execute_reply": "2026-02-28T18:25:45.778808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(delta_wide[\"delta_tpl\"], delta_wide[\"delta_ae\"],\n",
    "           color=COLORS[\"teal\"], s=50, alpha=0.7, edgecolors=\"white\", linewidth=0.5)\n",
    "\n",
    "# Highlight outliers\n",
    "if multi_outliers.any():\n",
    "    ax.scatter(delta_wide.loc[multi_outliers, \"delta_tpl\"],\n",
    "               delta_wide.loc[multi_outliers, \"delta_ae\"],\n",
    "               color=COLORS[\"pink_dark\"], s=80, alpha=0.9, edgecolors=\"black\",\n",
    "               linewidth=1, label=\"Outliers\", zorder=5)\n",
    "\n",
    "# Regression line\n",
    "slope, intercept = np.polyfit(delta_wide[\"delta_tpl\"], delta_wide[\"delta_ae\"], 1)\n",
    "x_line = np.linspace(delta_wide[\"delta_tpl\"].min(), delta_wide[\"delta_tpl\"].max(), 100)\n",
    "ax.plot(x_line, slope * x_line + intercept, color=\"grey\", linestyle=\"--\", linewidth=1.5)\n",
    "\n",
    "ax.axhline(0, color=\"black\", linewidth=0.5, alpha=0.3)\n",
    "ax.axvline(0, color=\"black\", linewidth=0.5, alpha=0.3)\n",
    "\n",
    "ax.set_xlabel(\"\\u0394 Time-per-Letter (s)\", fontsize=12)\n",
    "ax.set_ylabel(\"\\u0394 Absolute Error\", fontsize=12)\n",
    "ax.set_title(\"Disruption Correlation\", fontsize=14, fontweight=\"bold\")\n",
    "if multi_outliers.any():\n",
    "    ax.legend(fontsize=9)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:45.782566Z",
     "iopub.status.busy": "2026-02-28T18:25:45.782263Z",
     "iopub.status.idle": "2026-02-28T18:25:45.876214Z",
     "shell.execute_reply": "2026-02-28T18:25:45.875735Z"
    }
   },
   "outputs": [],
   "source": [
    "if multi_outliers.any():\n",
    "    delta_clean_vis = delta_wide[~multi_outliers].copy()\n",
    "    r_c, p_c = stats.pearsonr(delta_clean_vis[\"delta_tpl\"], delta_clean_vis[\"delta_ae\"])\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    ax = sns.regplot(data=delta_clean_vis, x='delta_tpl', y='delta_ae')\n",
    "    ax.set_title('Relationship of Disruption Metrics in Both Domains')\n",
    "    ax.set_xlabel('Performance Disruption (\\u0394 Time per Letter)')\n",
    "    ax.set_ylabel('Time Perception Disruption (\\u0394 Error)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:45.877629Z",
     "iopub.status.busy": "2026-02-28T18:25:45.877519Z",
     "iopub.status.idle": "2026-02-28T18:25:46.003530Z",
     "shell.execute_reply": "2026-02-28T18:25:46.003098Z"
    }
   },
   "outputs": [],
   "source": [
    "df_agg_by_complexity = df_clean.groupby(\n",
    "    ['participant_id', 'COND_nback_level', 'COND_interruption_condition']\n",
    ").agg(\n",
    "    avg_perf=('OUT_time_per_letter', 'mean'),\n",
    "    avg_time_error=('OUT_normalized_absolute_error', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "df_pivot = df_agg_by_complexity.pivot(\n",
    "    index=['participant_id', 'COND_nback_level'],\n",
    "    columns='COND_interruption_condition',\n",
    "    values=['avg_perf', 'avg_time_error']\n",
    ")\n",
    "df_pivot.columns = ['_'.join(col).strip() for col in df_pivot.columns.values]\n",
    "df_pivot = df_pivot.reset_index()\n",
    "\n",
    "df_pivot['delta_performance'] = df_pivot['avg_perf_interrupted'] - df_pivot['avg_perf_sequential']\n",
    "df_pivot['delta_time_error'] = df_pivot['avg_time_error_interrupted'] - df_pivot['avg_time_error_sequential']\n",
    "\n",
    "df_deltas_low = df_pivot.query(\"COND_nback_level == 1\").dropna()\n",
    "df_deltas_high = df_pivot.query(\"COND_nback_level == 2\").dropna()\n",
    "\n",
    "print(\"--- Correlation for LOW Complexity (1-back) ---\")\n",
    "corr_low = pg.corr(df_deltas_low['delta_performance'], df_deltas_low['delta_time_error'])\n",
    "display(corr_low)\n",
    "\n",
    "print(\"\\n--- Correlation for HIGH Complexity (2-back) ---\")\n",
    "corr_high = pg.corr(df_deltas_high['delta_performance'], df_deltas_high['delta_time_error'])\n",
    "display(corr_high)\n",
    "\n",
    "g = sns.lmplot(data=df_pivot, x='delta_performance', y='delta_time_error',\n",
    "               hue='COND_nback_level', height=6, legend=False)\n",
    "g.set_axis_labels('Performance Disruption (\u0394 Time per Letter)',\n",
    "                  'Time Perception Disruption (\u0394 Error)')\n",
    "g.figure.suptitle('Disruption Relationship by Task Complexity', fontsize=16, y=1.02)\n",
    "plt.legend(title='N-Back Level', labels=['1-Back (Low)', '2-Back (High)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T18:25:46.004707Z",
     "iopub.status.busy": "2026-02-28T18:25:46.004613Z",
     "iopub.status.idle": "2026-02-28T18:25:46.164217Z",
     "shell.execute_reply": "2026-02-28T18:25:46.163793Z"
    }
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "TIMING_DVS = ['mean_SO_ratio', 'cv_estimate']\n",
    "PERFORM_DVS = ['mean_time_per_letter', 'mean_typing_error']\n",
    "\n",
    "LABEL = {\n",
    "    'mean_SO_ratio': 'SO ratio',\n",
    "    'cv_estimate': 'CV',\n",
    "    'mean_time_per_letter': 'Time / letter',\n",
    "    'mean_typing_error': 'Typing err'\n",
    "}\n",
    "\n",
    "corr_df = agg_tp.merge(agg_perf[['participant_id', 'COND_interruption_condition',\n",
    "                                   'COND_nback_level', 'mean_time_per_letter', 'mean_typing_error']],\n",
    "                        on=['participant_id', 'COND_interruption_condition', 'COND_nback_level'],\n",
    "                        how='inner')\n",
    "\n",
    "n_rows = len(TIMING_DVS)\n",
    "n_cols = len(PERFORM_DVS)\n",
    "\n",
    "def prettify(var, width=14):\n",
    "    txt = LABEL.get(var, var).replace('_', ' ')\n",
    "    return '\\n'.join(textwrap.wrap(txt, width))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4.5 * n_rows))\n",
    "fig.subplots_adjust(wspace=0.40, hspace=0.40)\n",
    "\n",
    "for i, x in enumerate(TIMING_DVS):\n",
    "    for j, y in enumerate(PERFORM_DVS):\n",
    "        ax = axes[i][j] if n_rows > 1 else axes[j]\n",
    "        sub = corr_df[[SUBJECT, x, y]].dropna()\n",
    "\n",
    "        sub['x_c'] = sub[x] - sub.groupby(SUBJECT)[x].transform('mean')\n",
    "        sub['y_c'] = sub[y] - sub.groupby(SUBJECT)[y].transform('mean')\n",
    "\n",
    "        sns.scatterplot(data=sub, x='x_c', y='y_c', ax=ax, s=40,\n",
    "                        edgecolor='w', linewidth=.5, alpha=.75)\n",
    "\n",
    "        slope = (sub['x_c'] * sub['y_c']).sum() / (sub['x_c'] ** 2).sum()\n",
    "        xs = np.linspace(sub['x_c'].min(), sub['x_c'].max(), 100)\n",
    "        ax.plot(xs, slope * xs, lw=2, color='tab:blue')\n",
    "\n",
    "        stats_r = pg.rm_corr(data=sub, x=x, y=y, subject=SUBJECT).iloc[0]\n",
    "        ax.set_title(f\"{prettify(x)} vs {prettify(y)}\\n\"\n",
    "                     f\"r = {stats_r['r']:.2f}, p = {stats_r['pval']:.3g}\", fontsize=11)\n",
    "        ax.set_xlabel(f\"{prettify(x)}\")\n",
    "        ax.set_ylabel(f\"{prettify(y)}\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}